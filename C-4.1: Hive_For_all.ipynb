{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usshaa/SMBDA/blob/main/C-4.1%3A%20Hive_For_all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "cbbfcb6d-dbfd-4279-807a-fe15779676cc",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "3jcusF1lBers"
      },
      "source": [
        "### List Files in DBFS Hive Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "08a125dc-6bd5-46a5-a3f4-21ce80b6bdbd",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "BkgUqdgnBerw",
        "outputId": "7a3b84fc-7336-4ae0-977c-f4d31a1be7f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/user/hive/warehouse/</td><td>warehouse/</td><td>0</td><td>0</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  "dbfs:/user/hive/warehouse/",
                  "warehouse/",
                  0,
                  0
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "path",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "name",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "size",
                  "type": "\"long\""
                },
                {
                  "metadata": "{}",
                  "name": "modificationTime",
                  "type": "\"long\""
                }
              ],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%fs ls \"dbfs:/user/hive/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "d8efac58-0be5-4833-855b-e8d1ddba078d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "MHe9OGJBBerz"
      },
      "source": [
        "### **List Files in the Specified DBFS Directory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2077c0ba-84bd-4c70-8194-16276c4e6570",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "0WBlaAqUBer0",
        "outputId": "73c026a5-606d-450c-ac7e-a1b3fbf50bad"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/delivery_reviews/</td><td>delivery_reviews/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/FileStore/tables/mydata/</td><td>mydata/</td><td>0</td><td>0</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  "dbfs:/FileStore/tables/delivery_reviews/",
                  "delivery_reviews/",
                  0,
                  0
                ],
                [
                  "dbfs:/FileStore/tables/mydata/",
                  "mydata/",
                  0,
                  0
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "path",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "name",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "size",
                  "type": "\"long\""
                },
                {
                  "metadata": "{}",
                  "name": "modificationTime",
                  "type": "\"long\""
                }
              ],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%fs ls /FileStore/tables/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "b4392962-b71d-49ac-9000-fb0448a1f55d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "W1POyDhSBer1"
      },
      "source": [
        "### **Remove Directory and Its Contents in DBFS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8849d714-ca72-40e2-9d87-e089570cc413",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "D70elKMsBer2"
      },
      "outputs": [],
      "source": [
        "%sql\n",
        "-- %fs rm -r /FileStore/tables/mydata/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "70453160-5aa2-4a09-aa66-dd89daf6ac81",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "5ZAxMIyXBer3"
      },
      "source": [
        "### **Remove Hive Directory and Its Contents in DBFS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0313259f-675e-41e7-ba18-e97a53a5894e",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "IWN_X1JEBer4"
      },
      "outputs": [],
      "source": [
        "%sql\n",
        "-- %fs rm -r dbfs:/user/hive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "f2715c99-6bba-4711-9af8-56c160f4415f",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "PdsB_g74Ber4"
      },
      "source": [
        "### **Select Database and List All Tables**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "397680cf-8756-45cc-aae1-9472dd3263ea",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "EEv324XUBer5",
        "outputId": "e6a3ab12-6255-4767-99a8-e806240ce30a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>database</th><th>tableName</th><th>isTemporary</th></tr></thead><tbody><tr><td>my_hive_db</td><td>employee</td><td>false</td></tr><tr><td>my_hive_db</td><td>employee_cleaned</td><td>false</td></tr><tr><td>my_hive_db</td><td>employee_external</td><td>false</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  "my_hive_db",
                  "employee",
                  false
                ],
                [
                  "my_hive_db",
                  "employee_cleaned",
                  false
                ],
                [
                  "my_hive_db",
                  "employee_external",
                  false
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "database",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "tableName",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "isTemporary",
                  "type": "\"boolean\""
                }
              ],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "USE my_hive_db;\n",
        "SHOW TABLES;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "cd760de9-983f-467f-94bc-80d3cd9b1946",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "sFD94RYMBer6"
      },
      "source": [
        "### **Drop the Table Permanently from the Database**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f383edbd-58d7-4296-b6ca-70e30d66ca3b",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "ALmqQwxOBer6",
        "outputId": "2266611c-eda2-42dd-8c61-bcf0010a6d51"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "com.databricks.backend.common.rpc.SparkDriverExceptions$SQLExecutionException: org.apache.spark.sql.catalyst.analysis.NoSuchTableException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `spark_catalog`.`default`.`employee` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
              "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\n",
              "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.\n",
              "\tat org.apache.spark.sql.errors.QueryCompilationErrors$.noSuchTableError(QueryCompilationErrors.scala:1388)\n",
              "\tat org.apache.spark.sql.execution.command.DropTableCommand.run(ddl.scala:285)\n",
              "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:82)\n",
              "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n",
              "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:80)\n",
              "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:79)\n",
              "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:91)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:256)\n",
              "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:165)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:256)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$9(SQLExecution.scala:258)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:448)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:203)\n",
              "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:131)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:398)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:255)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:238)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:251)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:244)\n",
              "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:519)\n",
              "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:106)\n",
              "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:519)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:339)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:335)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
              "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:495)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:244)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:395)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:244)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:198)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:189)\n",
              "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:250)\n",
              "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:119)\n",
              "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n",
              "\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1080)\n",
              "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n",
              "\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1080)\n",
              "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:110)\n",
              "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:876)\n",
              "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n",
              "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:865)\n",
              "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:909)\n",
              "\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:695)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:265)\n",
              "\tat scala.collection.immutable.List.map(List.scala:293)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:211)\n",
              "\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:31)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$27(DriverLocal.scala:929)\n",
              "\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:125)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:920)\n",
              "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n",
              "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
              "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:77)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:77)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:889)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:719)\n",
              "\tat scala.util.Try$.apply(Try.scala:213)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:711)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:739)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:628)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:499)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)\n",
              "\tat java.lang.Thread.run(Thread.java:750)\n",
              "\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:309)\n",
              "\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:31)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$27(DriverLocal.scala:929)\n",
              "\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:125)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:920)\n",
              "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n",
              "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
              "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:77)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:77)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:889)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:719)\n",
              "\tat scala.util.Try$.apply(Try.scala:213)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:711)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:739)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:628)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:499)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)\n",
              "\tat java.lang.Thread.run(Thread.java:750)"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "com.databricks.backend.common.rpc.SparkDriverExceptions$SQLExecutionException: org.apache.spark.sql.catalyst.analysis.NoSuchTableException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `spark_catalog`.`default`.`employee` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.\n\tat org.apache.spark.sql.errors.QueryCompilationErrors$.noSuchTableError(QueryCompilationErrors.scala:1388)\n\tat org.apache.spark.sql.execution.command.DropTableCommand.run(ddl.scala:285)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:82)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:80)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:79)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:91)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:256)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:165)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:256)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$9(SQLExecution.scala:258)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:448)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:203)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:131)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:398)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:255)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:238)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:251)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:244)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:519)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:106)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:519)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:339)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:335)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:495)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:244)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:395)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:244)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:198)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:189)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:250)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:119)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1080)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1080)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:110)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:876)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:865)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:909)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:695)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:265)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:211)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:31)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$27(DriverLocal.scala:929)\n\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:125)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:920)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:77)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:77)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:889)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:719)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:711)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:739)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:628)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:499)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:309)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:31)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$27(DriverLocal.scala:929)\n\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:125)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:920)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:77)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:77)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:889)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:719)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:711)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:739)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:628)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:499)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)\n\tat java.lang.Thread.run(Thread.java:750)\n",
              "errorSummary": "NoSuchTableException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `spark_catalog`.`default`.`employee` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.",
              "errorTraceType": "html",
              "metadata": {},
              "type": "ipynbError"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "DROP TABLE employee;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a19fb53b-c900-41cc-91a0-3ad579e06fff",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "WSggCJuhBer6",
        "outputId": "0a4ff561-106b-4ff8-ddbb-ecfd6e222214"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "com.databricks.backend.common.rpc.SparkDriverExceptions$SQLExecutionException: org.apache.spark.sql.catalyst.analysis.NoSuchTableException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `spark_catalog`.`default`.`employee_external` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
              "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\n",
              "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.\n",
              "\tat org.apache.spark.sql.errors.QueryCompilationErrors$.noSuchTableError(QueryCompilationErrors.scala:1388)\n",
              "\tat org.apache.spark.sql.execution.command.DropTableCommand.run(ddl.scala:285)\n",
              "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:82)\n",
              "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n",
              "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:80)\n",
              "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:79)\n",
              "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:91)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:256)\n",
              "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:165)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:256)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$9(SQLExecution.scala:258)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:448)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:203)\n",
              "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:131)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:398)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:255)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:238)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:251)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:244)\n",
              "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:519)\n",
              "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:106)\n",
              "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:519)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:339)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:335)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
              "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:495)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:244)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:395)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:244)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:198)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:189)\n",
              "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:250)\n",
              "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:119)\n",
              "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n",
              "\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1080)\n",
              "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n",
              "\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1080)\n",
              "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:110)\n",
              "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:876)\n",
              "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n",
              "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:865)\n",
              "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:909)\n",
              "\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:695)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:265)\n",
              "\tat scala.collection.immutable.List.map(List.scala:293)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:211)\n",
              "\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:31)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$27(DriverLocal.scala:929)\n",
              "\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:125)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:920)\n",
              "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n",
              "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
              "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:77)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:77)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:889)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:719)\n",
              "\tat scala.util.Try$.apply(Try.scala:213)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:711)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:739)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:628)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:499)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)\n",
              "\tat java.lang.Thread.run(Thread.java:750)\n",
              "\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:309)\n",
              "\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:31)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$27(DriverLocal.scala:929)\n",
              "\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:125)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:920)\n",
              "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n",
              "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
              "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:77)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:77)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:889)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:719)\n",
              "\tat scala.util.Try$.apply(Try.scala:213)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:711)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:739)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:628)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:499)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)\n",
              "\tat java.lang.Thread.run(Thread.java:750)"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "com.databricks.backend.common.rpc.SparkDriverExceptions$SQLExecutionException: org.apache.spark.sql.catalyst.analysis.NoSuchTableException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `spark_catalog`.`default`.`employee_external` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.\n\tat org.apache.spark.sql.errors.QueryCompilationErrors$.noSuchTableError(QueryCompilationErrors.scala:1388)\n\tat org.apache.spark.sql.execution.command.DropTableCommand.run(ddl.scala:285)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:82)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:80)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:79)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:91)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:256)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:165)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:256)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$9(SQLExecution.scala:258)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:448)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:203)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:131)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:398)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:255)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:238)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:251)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:244)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:519)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:106)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:519)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:339)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:335)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:495)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:244)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:395)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:244)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:198)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:189)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:250)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:119)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1080)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1080)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:110)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:876)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:865)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:909)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:695)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:265)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:211)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:31)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$27(DriverLocal.scala:929)\n\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:125)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:920)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:77)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:77)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:889)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:719)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:711)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:739)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:628)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:499)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:309)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:31)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$27(DriverLocal.scala:929)\n\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:125)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:920)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:77)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:77)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:889)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:719)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:711)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:739)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:628)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:499)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)\n\tat java.lang.Thread.run(Thread.java:750)\n",
              "errorSummary": "NoSuchTableException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `spark_catalog`.`default`.`employee_external` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.",
              "errorTraceType": "html",
              "metadata": {},
              "type": "ipynbError"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "DROP TABLE employee_external;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "2ba4962a-41fc-4e96-8557-84bb18cf79c1",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "XGG0ZMJ1Ber6"
      },
      "source": [
        "### **Drop the Database (Fails if It Contains Tables)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f9818107-5552-4003-9a55-90af5c76996b",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "cmxDaTYABer7",
        "outputId": "7c413fa8-e9f8-4c1f-cfed-e5b14aa2c1b7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "com.databricks.backend.common.rpc.SparkDriverExceptions$SQLExecutionException: org.apache.spark.sql.catalyst.analysis.NoSuchNamespaceException: [SCHEMA_NOT_FOUND] The schema `my_hive_db` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
              "If you did not qualify the name with a catalog, verify the current_schema() output, or qualify the name with the correct catalog.\n",
              "To tolerate the error on drop use DROP SCHEMA IF EXISTS.\n",
              "\tat org.apache.spark.sql.errors.QueryCompilationErrors$.noSuchNamespaceError(QueryCompilationErrors.scala:1392)\n",
              "\tat org.apache.spark.sql.execution.datasources.v2.DropNamespaceExec.run(DropNamespaceExec.scala:48)\n",
              "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$1(V2CommandExec.scala:47)\n",
              "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n",
              "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:47)\n",
              "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:45)\n",
              "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:54)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:256)\n",
              "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:165)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:256)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$9(SQLExecution.scala:258)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:448)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:203)\n",
              "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:131)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:398)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:255)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:238)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:251)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:244)\n",
              "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:519)\n",
              "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:106)\n",
              "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:519)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:339)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:335)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
              "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:495)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:244)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:395)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:244)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:198)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:189)\n",
              "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:250)\n",
              "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:119)\n",
              "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n",
              "\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1080)\n",
              "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n",
              "\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1080)\n",
              "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:110)\n",
              "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:876)\n",
              "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n",
              "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:865)\n",
              "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:909)\n",
              "\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:695)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:265)\n",
              "\tat scala.collection.immutable.List.map(List.scala:293)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:211)\n",
              "\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:31)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$27(DriverLocal.scala:929)\n",
              "\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:125)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:920)\n",
              "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n",
              "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
              "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:77)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:77)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:889)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:719)\n",
              "\tat scala.util.Try$.apply(Try.scala:213)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:711)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:739)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:628)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:499)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)\n",
              "\tat java.lang.Thread.run(Thread.java:750)\n",
              "\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:309)\n",
              "\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:31)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$27(DriverLocal.scala:929)\n",
              "\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:125)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:920)\n",
              "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n",
              "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
              "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:77)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:77)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:889)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:719)\n",
              "\tat scala.util.Try$.apply(Try.scala:213)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:711)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:739)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:628)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:499)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)\n",
              "\tat java.lang.Thread.run(Thread.java:750)"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "com.databricks.backend.common.rpc.SparkDriverExceptions$SQLExecutionException: org.apache.spark.sql.catalyst.analysis.NoSuchNamespaceException: [SCHEMA_NOT_FOUND] The schema `my_hive_db` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a catalog, verify the current_schema() output, or qualify the name with the correct catalog.\nTo tolerate the error on drop use DROP SCHEMA IF EXISTS.\n\tat org.apache.spark.sql.errors.QueryCompilationErrors$.noSuchNamespaceError(QueryCompilationErrors.scala:1392)\n\tat org.apache.spark.sql.execution.datasources.v2.DropNamespaceExec.run(DropNamespaceExec.scala:48)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$1(V2CommandExec.scala:47)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:47)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:45)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:54)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:256)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:165)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:256)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$9(SQLExecution.scala:258)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:448)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:203)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:131)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:398)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:255)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:238)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:251)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:244)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:519)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:106)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:519)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:339)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:335)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:495)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:244)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:395)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:244)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:198)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:189)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:250)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:119)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1080)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1080)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:110)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:876)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:865)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:909)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:695)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:265)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:211)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:31)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$27(DriverLocal.scala:929)\n\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:125)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:920)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:77)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:77)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:889)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:719)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:711)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:739)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:628)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:499)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:309)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:31)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$27(DriverLocal.scala:929)\n\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:125)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:920)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:77)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:77)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:889)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:719)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:711)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:739)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:628)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:499)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)\n\tat java.lang.Thread.run(Thread.java:750)\n",
              "errorSummary": "NoSuchNamespaceException: [SCHEMA_NOT_FOUND] The schema `my_hive_db` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a catalog, verify the current_schema() output, or qualify the name with the correct catalog.\nTo tolerate the error on drop use DROP SCHEMA IF EXISTS.",
              "errorTraceType": "html",
              "metadata": {},
              "type": "ipynbError"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "DROP DATABASE my_hive_db;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "4ca53c41-5ac4-4b46-9d09-11bf4b8c5470",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "uCq5fG7aBer7"
      },
      "source": [
        "### **Drop the Database  Verify the spelling and correctness of the schema and catalog.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3d65a4f6-d687-4f06-83da-6ac1d60b9409",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "SognhgAgBer8",
        "outputId": "6f029c44-ce5d-4965-8efe-1d88d3140098"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "com.databricks.backend.common.rpc.SparkDriverExceptions$SQLExecutionException: org.apache.spark.sql.catalyst.analysis.NoSuchNamespaceException: [SCHEMA_NOT_FOUND] The schema `my_hive_db` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
              "If you did not qualify the name with a catalog, verify the current_schema() output, or qualify the name with the correct catalog.\n",
              "To tolerate the error on drop use DROP SCHEMA IF EXISTS.\n",
              "\tat org.apache.spark.sql.errors.QueryCompilationErrors$.noSuchNamespaceError(QueryCompilationErrors.scala:1392)\n",
              "\tat org.apache.spark.sql.execution.datasources.v2.DropNamespaceExec.run(DropNamespaceExec.scala:48)\n",
              "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$1(V2CommandExec.scala:47)\n",
              "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n",
              "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:47)\n",
              "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:45)\n",
              "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:54)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:256)\n",
              "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:165)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:256)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$9(SQLExecution.scala:258)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:448)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:203)\n",
              "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:131)\n",
              "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:398)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:255)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:238)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:251)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:244)\n",
              "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:519)\n",
              "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:106)\n",
              "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:519)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:339)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:335)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
              "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:495)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:244)\n",
              "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:395)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:244)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:198)\n",
              "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:189)\n",
              "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:250)\n",
              "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:119)\n",
              "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n",
              "\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1080)\n",
              "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n",
              "\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1080)\n",
              "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:110)\n",
              "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:876)\n",
              "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n",
              "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:865)\n",
              "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:909)\n",
              "\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:695)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:265)\n",
              "\tat scala.collection.immutable.List.map(List.scala:293)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:211)\n",
              "\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:31)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$27(DriverLocal.scala:929)\n",
              "\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:125)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:920)\n",
              "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n",
              "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
              "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:77)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:77)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:889)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:719)\n",
              "\tat scala.util.Try$.apply(Try.scala:213)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:711)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:739)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:628)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:499)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)\n",
              "\tat java.lang.Thread.run(Thread.java:750)\n",
              "\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:309)\n",
              "\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:31)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$27(DriverLocal.scala:929)\n",
              "\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:125)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:920)\n",
              "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n",
              "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
              "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:77)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:77)\n",
              "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:889)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:719)\n",
              "\tat scala.util.Try$.apply(Try.scala:213)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:711)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:739)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:628)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:499)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)\n",
              "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)\n",
              "\tat java.lang.Thread.run(Thread.java:750)"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "com.databricks.backend.common.rpc.SparkDriverExceptions$SQLExecutionException: org.apache.spark.sql.catalyst.analysis.NoSuchNamespaceException: [SCHEMA_NOT_FOUND] The schema `my_hive_db` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a catalog, verify the current_schema() output, or qualify the name with the correct catalog.\nTo tolerate the error on drop use DROP SCHEMA IF EXISTS.\n\tat org.apache.spark.sql.errors.QueryCompilationErrors$.noSuchNamespaceError(QueryCompilationErrors.scala:1392)\n\tat org.apache.spark.sql.execution.datasources.v2.DropNamespaceExec.run(DropNamespaceExec.scala:48)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$1(V2CommandExec.scala:47)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:47)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:45)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:54)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:256)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:165)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:256)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$9(SQLExecution.scala:258)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:448)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:203)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:131)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:398)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:255)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:238)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:251)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:244)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:519)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:106)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:519)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:339)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:335)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:495)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:244)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:395)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:244)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:198)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:189)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:250)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:119)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1080)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1080)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:110)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:876)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:865)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:909)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:695)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:265)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:211)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:31)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$27(DriverLocal.scala:929)\n\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:125)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:920)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:77)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:77)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:889)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:719)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:711)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:739)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:628)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:499)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:309)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:31)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$27(DriverLocal.scala:929)\n\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:125)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:920)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:77)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:77)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:889)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:719)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:711)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:739)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:628)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:663)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:499)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:438)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:262)\n\tat java.lang.Thread.run(Thread.java:750)\n",
              "errorSummary": "NoSuchNamespaceException: [SCHEMA_NOT_FOUND] The schema `my_hive_db` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a catalog, verify the current_schema() output, or qualify the name with the correct catalog.\nTo tolerate the error on drop use DROP SCHEMA IF EXISTS.",
              "errorTraceType": "html",
              "metadata": {},
              "type": "ipynbError"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "DROP DATABASE my_hive_db CASCADE;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "7205ddb4-6708-443f-a115-ae3a0bdc3e89",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "MZwmz5S5Ber8"
      },
      "source": [
        "### **Create Database if Not Exists and Select It**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c9fae95b-c388-4352-a464-9547be3ad5f2",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "axjtIU1tBer9",
        "outputId": "efa052cd-7bbf-4be8-c69e-457f9b2d521e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "CREATE DATABASE IF NOT EXISTS my_hive_db;\n",
        "USE my_hive_db;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "ea21c7d5-bb0b-4729-9134-80043c85734d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "xRXGcEdCBer9"
      },
      "source": [
        "### **Create a Table in Hive Using Parquet Format**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6c6cbfc7-2957-4184-9e88-596bbff9920d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "jv3X_-8zBer-",
        "outputId": "26f68365-543c-44af-8d55-275316c3da69"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "CREATE TABLE IF NOT EXISTS employee (\n",
        "    id INT,\n",
        "    name STRING,\n",
        "    age INT,\n",
        "    department STRING\n",
        ")\n",
        "USING PARQUET;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "3279697f-dc95-4e02-b702-44b128609d5d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "xnxmnWCHBer_"
      },
      "source": [
        "### **Insert Records into the Employee Table**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "47f0b9dc-45e4-4461-b898-ab38db6cac2e",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "ksvG9BR3Ber_",
        "outputId": "d6cb7963-9d47-46b3-b72f-a0b4ffc032df"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "INSERT INTO employee VALUES\n",
        "(1, 'John Doe', 30, 'Finance'),\n",
        "(2, 'Jane Smith', 25, 'IT');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "3bf65279-6972-4951-a29d-89894bdcfb22",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "SzXVG9EPBer_"
      },
      "source": [
        "### **Retrieve All Records from the Employee Table**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "cdd9a7a4-b3cd-42ab-ad4d-c1f60ac46eb1",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "JglTBsPJBer_",
        "outputId": "d27dfe37-3d96-42b9-b52c-6d4a48c13e8a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>age</th><th>department</th></tr></thead><tbody><tr><td>1</td><td>John Doe</td><td>30</td><td>Finance</td></tr><tr><td>2</td><td>Jane Smith</td><td>25</td><td>IT</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  1,
                  "John Doe",
                  30,
                  "Finance"
                ],
                [
                  2,
                  "Jane Smith",
                  25,
                  "IT"
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "id",
                  "type": "\"integer\""
                },
                {
                  "metadata": "{}",
                  "name": "name",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "age",
                  "type": "\"integer\""
                },
                {
                  "metadata": "{}",
                  "name": "department",
                  "type": "\"string\""
                }
              ],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "SELECT * FROM employee;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "712213a5-abcf-423f-afea-b5618aa3ad57",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "BkXJ0QDlBer_"
      },
      "source": [
        "### **Create an External Table in Hive with CSV Data Storage**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c813d618-e265-4b92-a1e9-173f2776c438",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "fPzeMo3WBesA",
        "outputId": "9148aa7d-3978-4910-8ba1-7f549f83aff0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "CREATE EXTERNAL TABLE my_hive_db.employee_external (\n",
        "    ID INT,\n",
        "    Name STRING,\n",
        "    Age INT,\n",
        "    Department STRING,\n",
        "    Salary DOUBLE,\n",
        "    Joining_Date DATE\n",
        ")\n",
        "ROW FORMAT DELIMITED\n",
        "FIELDS TERMINATED BY ','\n",
        "STORED AS TEXTFILE\n",
        "LOCATION 'dbfs:/FileStore/tables/mydata/'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "ccf451a0-5e6f-4883-aa71-7ab0f11cbe19",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "G6lB5ChkBesA"
      },
      "source": [
        "### **Load CSV Data from DBFS into the External Hive Table**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0bc979f9-5334-457c-84b2-d933a2aa1ce5",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "S4PjW74UBesA",
        "outputId": "cdba62d2-bcac-4bff-8575-36bd5377bebd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "LOAD DATA INPATH 'dbfs:/FileStore/tables/mydata/employee.csv' INTO TABLE employee_external;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "e35bd140-f052-45ab-9aa7-b86e2f279a77",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "0GNO-K1KBesB"
      },
      "source": [
        "### **Retrieve All Records from the External Employee Table**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "15aa4beb-5b92-4cd8-b634-6b5f4a39afc2",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "T1N7hdLpBesB",
        "outputId": "64f02dc7-1f72-49df-a807-ac2a6b690406"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>Name</th><th>Age</th><th>Department</th><th>Salary</th><th>Joining_Date</th></tr></thead><tbody><tr><td>null</td><td>Name</td><td>null</td><td>Department</td><td>null</td><td>null</td></tr><tr><td>1</td><td>Miranda Johnson</td><td>58</td><td>Engineering</td><td>119469.22</td><td>2022-02-21</td></tr><tr><td>2</td><td>Ryan Lee</td><td>55</td><td>Engineering</td><td>102336.05</td><td>2019-05-22</td></tr><tr><td>3</td><td>William Torres</td><td>49</td><td>Marketing</td><td>38991.2</td><td>2022-07-25</td></tr><tr><td>4</td><td>Brittany Hernandez</td><td>44</td><td>IT</td><td>42585.89</td><td>2019-12-07</td></tr><tr><td>5</td><td>Megan Cherry</td><td>50</td><td>Finance</td><td>41944.9</td><td>2024-08-02</td></tr><tr><td>6</td><td>Samuel Daniels</td><td>60</td><td>Sales</td><td>63854.4</td><td>2020-07-22</td></tr><tr><td>7</td><td>Harold Everett</td><td>35</td><td>Finance</td><td>61779.53</td><td>2021-10-29</td></tr><tr><td>8</td><td>Pam Ruiz</td><td>30</td><td>Marketing</td><td>118795.78</td><td>2020-06-12</td></tr><tr><td>9</td><td>Kristin Rodriguez</td><td>53</td><td>Engineering</td><td>86175.05</td><td>2018-07-16</td></tr><tr><td>10</td><td>Scott Murphy</td><td>30</td><td>Engineering</td><td>76038.39</td><td>2024-02-14</td></tr><tr><td>11</td><td>Richard Jacobs</td><td>54</td><td>Marketing</td><td>77725.84</td><td>2023-03-22</td></tr><tr><td>12</td><td>Keith Diaz</td><td>60</td><td>Marketing</td><td>81059.96</td><td>2019-07-12</td></tr><tr><td>13</td><td>Christopher Pruitt</td><td>52</td><td>Sales</td><td>113644.09</td><td>2019-10-18</td></tr><tr><td>14</td><td>Benjamin Carter</td><td>50</td><td>Finance</td><td>44996.07</td><td>2024-06-21</td></tr><tr><td>15</td><td>Joseph Everett</td><td>47</td><td>Marketing</td><td>43383.14</td><td>2021-11-24</td></tr><tr><td>16</td><td>Gina Martinez</td><td>22</td><td>Marketing</td><td>106480.2</td><td>2017-12-26</td></tr><tr><td>17</td><td>Jessica Herrera DDS</td><td>51</td><td>Marketing</td><td>79347.77</td><td>2017-10-11</td></tr><tr><td>18</td><td>Stephen Taylor</td><td>51</td><td>Finance</td><td>110841.74</td><td>2022-09-26</td></tr><tr><td>19</td><td>Danielle Kelly</td><td>48</td><td>HR</td><td>100780.62</td><td>2017-07-18</td></tr><tr><td>20</td><td>Dr. Christopher Steele</td><td>27</td><td>Finance</td><td>116648.26</td><td>2018-06-30</td></tr><tr><td>21</td><td>Kevin Leonard</td><td>60</td><td>Sales</td><td>77036.71</td><td>2025-01-15</td></tr><tr><td>22</td><td>Shannon Brown</td><td>42</td><td>HR</td><td>67540.92</td><td>2024-11-24</td></tr><tr><td>23</td><td>Joseph Perez</td><td>24</td><td>IT</td><td>31429.97</td><td>2024-10-31</td></tr><tr><td>24</td><td>Jessica Goodwin</td><td>50</td><td>Engineering</td><td>85431.77</td><td>2023-05-30</td></tr><tr><td>25</td><td>James Dunn</td><td>53</td><td>Engineering</td><td>75625.22</td><td>2022-09-10</td></tr><tr><td>26</td><td>Julie Welch</td><td>40</td><td>Finance</td><td>43267.67</td><td>2017-04-24</td></tr><tr><td>27</td><td>Darin Mcbride</td><td>44</td><td>HR</td><td>53767.03</td><td>2020-03-26</td></tr><tr><td>28</td><td>Kristen Thompson</td><td>38</td><td>IT</td><td>105263.19</td><td>2023-05-30</td></tr><tr><td>29</td><td>Erin Graves</td><td>36</td><td>Sales</td><td>63082.92</td><td>2023-09-14</td></tr><tr><td>30</td><td>Eric Sparks</td><td>45</td><td>IT</td><td>119771.68</td><td>2024-07-15</td></tr><tr><td>31</td><td>Kimberly Beasley</td><td>40</td><td>Marketing</td><td>79804.86</td><td>2021-06-22</td></tr><tr><td>32</td><td>Gary Brown Jr.</td><td>60</td><td>Engineering</td><td>72747.45</td><td>2019-05-27</td></tr><tr><td>33</td><td>Sean Lowery</td><td>29</td><td>IT</td><td>48469.72</td><td>2020-09-13</td></tr><tr><td>34</td><td>Andre Andrade</td><td>58</td><td>Engineering</td><td>116103.39</td><td>2020-01-02</td></tr><tr><td>35</td><td>Christopher Garcia</td><td>27</td><td>Marketing</td><td>116163.3</td><td>2018-07-20</td></tr><tr><td>36</td><td>Rachel Valentine</td><td>53</td><td>Marketing</td><td>107012.86</td><td>2016-11-22</td></tr><tr><td>37</td><td>Jill Tucker</td><td>32</td><td>Engineering</td><td>104794.25</td><td>2015-10-26</td></tr><tr><td>38</td><td>Donald Perez</td><td>28</td><td>Sales</td><td>57328.59</td><td>2017-12-30</td></tr><tr><td>39</td><td>Adrienne Gonzalez</td><td>56</td><td>IT</td><td>102891.39</td><td>2020-02-28</td></tr><tr><td>40</td><td>Joseph Shannon</td><td>50</td><td>IT</td><td>58684.97</td><td>2022-03-26</td></tr><tr><td>41</td><td>Robert Bennett</td><td>60</td><td>Marketing</td><td>84853.13</td><td>2016-11-03</td></tr><tr><td>42</td><td>Angela Diaz</td><td>35</td><td>Finance</td><td>36282.1</td><td>2019-01-25</td></tr><tr><td>43</td><td>Billy Li</td><td>52</td><td>Finance</td><td>37680.52</td><td>2024-06-10</td></tr><tr><td>44</td><td>Sean Franklin</td><td>36</td><td>Engineering</td><td>63291.29</td><td>2015-11-30</td></tr><tr><td>45</td><td>Peter Harding</td><td>57</td><td>Finance</td><td>82761.83</td><td>2019-10-21</td></tr><tr><td>46</td><td>Charles Johnson</td><td>45</td><td>Engineering</td><td>114542.55</td><td>2024-09-20</td></tr><tr><td>47</td><td>Michael Martinez</td><td>60</td><td>Finance</td><td>91040.52</td><td>2018-09-17</td></tr><tr><td>48</td><td>Joshua Johnson</td><td>38</td><td>Marketing</td><td>78569.11</td><td>2018-09-18</td></tr><tr><td>49</td><td>Kevin Lee MD</td><td>24</td><td>IT</td><td>117533.18</td><td>2017-10-04</td></tr><tr><td>50</td><td>Scott Anderson</td><td>38</td><td>Finance</td><td>41064.06</td><td>2023-06-30</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  null,
                  "Name",
                  null,
                  "Department",
                  null,
                  null
                ],
                [
                  1,
                  "Miranda Johnson",
                  58,
                  "Engineering",
                  119469.22,
                  "2022-02-21"
                ],
                [
                  2,
                  "Ryan Lee",
                  55,
                  "Engineering",
                  102336.05,
                  "2019-05-22"
                ],
                [
                  3,
                  "William Torres",
                  49,
                  "Marketing",
                  38991.2,
                  "2022-07-25"
                ],
                [
                  4,
                  "Brittany Hernandez",
                  44,
                  "IT",
                  42585.89,
                  "2019-12-07"
                ],
                [
                  5,
                  "Megan Cherry",
                  50,
                  "Finance",
                  41944.9,
                  "2024-08-02"
                ],
                [
                  6,
                  "Samuel Daniels",
                  60,
                  "Sales",
                  63854.4,
                  "2020-07-22"
                ],
                [
                  7,
                  "Harold Everett",
                  35,
                  "Finance",
                  61779.53,
                  "2021-10-29"
                ],
                [
                  8,
                  "Pam Ruiz",
                  30,
                  "Marketing",
                  118795.78,
                  "2020-06-12"
                ],
                [
                  9,
                  "Kristin Rodriguez",
                  53,
                  "Engineering",
                  86175.05,
                  "2018-07-16"
                ],
                [
                  10,
                  "Scott Murphy",
                  30,
                  "Engineering",
                  76038.39,
                  "2024-02-14"
                ],
                [
                  11,
                  "Richard Jacobs",
                  54,
                  "Marketing",
                  77725.84,
                  "2023-03-22"
                ],
                [
                  12,
                  "Keith Diaz",
                  60,
                  "Marketing",
                  81059.96,
                  "2019-07-12"
                ],
                [
                  13,
                  "Christopher Pruitt",
                  52,
                  "Sales",
                  113644.09,
                  "2019-10-18"
                ],
                [
                  14,
                  "Benjamin Carter",
                  50,
                  "Finance",
                  44996.07,
                  "2024-06-21"
                ],
                [
                  15,
                  "Joseph Everett",
                  47,
                  "Marketing",
                  43383.14,
                  "2021-11-24"
                ],
                [
                  16,
                  "Gina Martinez",
                  22,
                  "Marketing",
                  106480.2,
                  "2017-12-26"
                ],
                [
                  17,
                  "Jessica Herrera DDS",
                  51,
                  "Marketing",
                  79347.77,
                  "2017-10-11"
                ],
                [
                  18,
                  "Stephen Taylor",
                  51,
                  "Finance",
                  110841.74,
                  "2022-09-26"
                ],
                [
                  19,
                  "Danielle Kelly",
                  48,
                  "HR",
                  100780.62,
                  "2017-07-18"
                ],
                [
                  20,
                  "Dr. Christopher Steele",
                  27,
                  "Finance",
                  116648.26,
                  "2018-06-30"
                ],
                [
                  21,
                  "Kevin Leonard",
                  60,
                  "Sales",
                  77036.71,
                  "2025-01-15"
                ],
                [
                  22,
                  "Shannon Brown",
                  42,
                  "HR",
                  67540.92,
                  "2024-11-24"
                ],
                [
                  23,
                  "Joseph Perez",
                  24,
                  "IT",
                  31429.97,
                  "2024-10-31"
                ],
                [
                  24,
                  "Jessica Goodwin",
                  50,
                  "Engineering",
                  85431.77,
                  "2023-05-30"
                ],
                [
                  25,
                  "James Dunn",
                  53,
                  "Engineering",
                  75625.22,
                  "2022-09-10"
                ],
                [
                  26,
                  "Julie Welch",
                  40,
                  "Finance",
                  43267.67,
                  "2017-04-24"
                ],
                [
                  27,
                  "Darin Mcbride",
                  44,
                  "HR",
                  53767.03,
                  "2020-03-26"
                ],
                [
                  28,
                  "Kristen Thompson",
                  38,
                  "IT",
                  105263.19,
                  "2023-05-30"
                ],
                [
                  29,
                  "Erin Graves",
                  36,
                  "Sales",
                  63082.92,
                  "2023-09-14"
                ],
                [
                  30,
                  "Eric Sparks",
                  45,
                  "IT",
                  119771.68,
                  "2024-07-15"
                ],
                [
                  31,
                  "Kimberly Beasley",
                  40,
                  "Marketing",
                  79804.86,
                  "2021-06-22"
                ],
                [
                  32,
                  "Gary Brown Jr.",
                  60,
                  "Engineering",
                  72747.45,
                  "2019-05-27"
                ],
                [
                  33,
                  "Sean Lowery",
                  29,
                  "IT",
                  48469.72,
                  "2020-09-13"
                ],
                [
                  34,
                  "Andre Andrade",
                  58,
                  "Engineering",
                  116103.39,
                  "2020-01-02"
                ],
                [
                  35,
                  "Christopher Garcia",
                  27,
                  "Marketing",
                  116163.3,
                  "2018-07-20"
                ],
                [
                  36,
                  "Rachel Valentine",
                  53,
                  "Marketing",
                  107012.86,
                  "2016-11-22"
                ],
                [
                  37,
                  "Jill Tucker",
                  32,
                  "Engineering",
                  104794.25,
                  "2015-10-26"
                ],
                [
                  38,
                  "Donald Perez",
                  28,
                  "Sales",
                  57328.59,
                  "2017-12-30"
                ],
                [
                  39,
                  "Adrienne Gonzalez",
                  56,
                  "IT",
                  102891.39,
                  "2020-02-28"
                ],
                [
                  40,
                  "Joseph Shannon",
                  50,
                  "IT",
                  58684.97,
                  "2022-03-26"
                ],
                [
                  41,
                  "Robert Bennett",
                  60,
                  "Marketing",
                  84853.13,
                  "2016-11-03"
                ],
                [
                  42,
                  "Angela Diaz",
                  35,
                  "Finance",
                  36282.1,
                  "2019-01-25"
                ],
                [
                  43,
                  "Billy Li",
                  52,
                  "Finance",
                  37680.52,
                  "2024-06-10"
                ],
                [
                  44,
                  "Sean Franklin",
                  36,
                  "Engineering",
                  63291.29,
                  "2015-11-30"
                ],
                [
                  45,
                  "Peter Harding",
                  57,
                  "Finance",
                  82761.83,
                  "2019-10-21"
                ],
                [
                  46,
                  "Charles Johnson",
                  45,
                  "Engineering",
                  114542.55,
                  "2024-09-20"
                ],
                [
                  47,
                  "Michael Martinez",
                  60,
                  "Finance",
                  91040.52,
                  "2018-09-17"
                ],
                [
                  48,
                  "Joshua Johnson",
                  38,
                  "Marketing",
                  78569.11,
                  "2018-09-18"
                ],
                [
                  49,
                  "Kevin Lee MD",
                  24,
                  "IT",
                  117533.18,
                  "2017-10-04"
                ],
                [
                  50,
                  "Scott Anderson",
                  38,
                  "Finance",
                  41064.06,
                  "2023-06-30"
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "ID",
                  "type": "\"integer\""
                },
                {
                  "metadata": "{}",
                  "name": "Name",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "Age",
                  "type": "\"integer\""
                },
                {
                  "metadata": "{}",
                  "name": "Department",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "Salary",
                  "type": "\"double\""
                },
                {
                  "metadata": "{}",
                  "name": "Joining_Date",
                  "type": "\"date\""
                }
              ],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "SELECT * FROM employee_external;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "a6b665c8-05e1-49f1-af64-d116453d995a",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "MmZo6arvBesB"
      },
      "source": [
        "### **Create a New Table with Cleaned Data by Removing Null IDs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3a416d03-f978-4851-9b30-485d601e4160",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "bxc1d9dDBesC",
        "outputId": "be10f070-b86b-4f54-a28e-fd8ecf46f9f9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "num_affected_rows",
                  "type": "\"long\""
                },
                {
                  "metadata": "{}",
                  "name": "num_inserted_rows",
                  "type": "\"long\""
                }
              ],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "CREATE TABLE my_hive_db.employee_cleaned AS\n",
        "SELECT * FROM my_hive_db.employee_external WHERE ID IS NOT NULL;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "8ef4d3bd-108d-4e8e-9c7e-f923baf21923",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "Eh0pzMihBesD"
      },
      "source": [
        "### **Retrieve All Records from the Cleaned Employee Table**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0ecd7faa-b03a-4eba-a52f-b9b62f16934e",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "MoZyptS4BesD",
        "outputId": "1e831cbf-7757-4835-b3f1-029ea07dce2a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>Name</th><th>Age</th><th>Department</th><th>Salary</th><th>Joining_Date</th></tr></thead><tbody><tr><td>1</td><td>Miranda Johnson</td><td>58</td><td>Engineering</td><td>119469.22</td><td>2022-02-21</td></tr><tr><td>2</td><td>Ryan Lee</td><td>55</td><td>Engineering</td><td>102336.05</td><td>2019-05-22</td></tr><tr><td>3</td><td>William Torres</td><td>49</td><td>Marketing</td><td>38991.2</td><td>2022-07-25</td></tr><tr><td>4</td><td>Brittany Hernandez</td><td>44</td><td>IT</td><td>42585.89</td><td>2019-12-07</td></tr><tr><td>5</td><td>Megan Cherry</td><td>50</td><td>Finance</td><td>41944.9</td><td>2024-08-02</td></tr><tr><td>6</td><td>Samuel Daniels</td><td>60</td><td>Sales</td><td>63854.4</td><td>2020-07-22</td></tr><tr><td>7</td><td>Harold Everett</td><td>35</td><td>Finance</td><td>61779.53</td><td>2021-10-29</td></tr><tr><td>8</td><td>Pam Ruiz</td><td>30</td><td>Marketing</td><td>118795.78</td><td>2020-06-12</td></tr><tr><td>9</td><td>Kristin Rodriguez</td><td>53</td><td>Engineering</td><td>86175.05</td><td>2018-07-16</td></tr><tr><td>10</td><td>Scott Murphy</td><td>30</td><td>Engineering</td><td>76038.39</td><td>2024-02-14</td></tr><tr><td>11</td><td>Richard Jacobs</td><td>54</td><td>Marketing</td><td>77725.84</td><td>2023-03-22</td></tr><tr><td>12</td><td>Keith Diaz</td><td>60</td><td>Marketing</td><td>81059.96</td><td>2019-07-12</td></tr><tr><td>13</td><td>Christopher Pruitt</td><td>52</td><td>Sales</td><td>113644.09</td><td>2019-10-18</td></tr><tr><td>14</td><td>Benjamin Carter</td><td>50</td><td>Finance</td><td>44996.07</td><td>2024-06-21</td></tr><tr><td>15</td><td>Joseph Everett</td><td>47</td><td>Marketing</td><td>43383.14</td><td>2021-11-24</td></tr><tr><td>16</td><td>Gina Martinez</td><td>22</td><td>Marketing</td><td>106480.2</td><td>2017-12-26</td></tr><tr><td>17</td><td>Jessica Herrera DDS</td><td>51</td><td>Marketing</td><td>79347.77</td><td>2017-10-11</td></tr><tr><td>18</td><td>Stephen Taylor</td><td>51</td><td>Finance</td><td>110841.74</td><td>2022-09-26</td></tr><tr><td>19</td><td>Danielle Kelly</td><td>48</td><td>HR</td><td>100780.62</td><td>2017-07-18</td></tr><tr><td>20</td><td>Dr. Christopher Steele</td><td>27</td><td>Finance</td><td>116648.26</td><td>2018-06-30</td></tr><tr><td>21</td><td>Kevin Leonard</td><td>60</td><td>Sales</td><td>77036.71</td><td>2025-01-15</td></tr><tr><td>22</td><td>Shannon Brown</td><td>42</td><td>HR</td><td>67540.92</td><td>2024-11-24</td></tr><tr><td>23</td><td>Joseph Perez</td><td>24</td><td>IT</td><td>31429.97</td><td>2024-10-31</td></tr><tr><td>24</td><td>Jessica Goodwin</td><td>50</td><td>Engineering</td><td>85431.77</td><td>2023-05-30</td></tr><tr><td>25</td><td>James Dunn</td><td>53</td><td>Engineering</td><td>75625.22</td><td>2022-09-10</td></tr><tr><td>26</td><td>Julie Welch</td><td>40</td><td>Finance</td><td>43267.67</td><td>2017-04-24</td></tr><tr><td>27</td><td>Darin Mcbride</td><td>44</td><td>HR</td><td>53767.03</td><td>2020-03-26</td></tr><tr><td>28</td><td>Kristen Thompson</td><td>38</td><td>IT</td><td>105263.19</td><td>2023-05-30</td></tr><tr><td>29</td><td>Erin Graves</td><td>36</td><td>Sales</td><td>63082.92</td><td>2023-09-14</td></tr><tr><td>30</td><td>Eric Sparks</td><td>45</td><td>IT</td><td>119771.68</td><td>2024-07-15</td></tr><tr><td>31</td><td>Kimberly Beasley</td><td>40</td><td>Marketing</td><td>79804.86</td><td>2021-06-22</td></tr><tr><td>32</td><td>Gary Brown Jr.</td><td>60</td><td>Engineering</td><td>72747.45</td><td>2019-05-27</td></tr><tr><td>33</td><td>Sean Lowery</td><td>29</td><td>IT</td><td>48469.72</td><td>2020-09-13</td></tr><tr><td>34</td><td>Andre Andrade</td><td>58</td><td>Engineering</td><td>116103.39</td><td>2020-01-02</td></tr><tr><td>35</td><td>Christopher Garcia</td><td>27</td><td>Marketing</td><td>116163.3</td><td>2018-07-20</td></tr><tr><td>36</td><td>Rachel Valentine</td><td>53</td><td>Marketing</td><td>107012.86</td><td>2016-11-22</td></tr><tr><td>37</td><td>Jill Tucker</td><td>32</td><td>Engineering</td><td>104794.25</td><td>2015-10-26</td></tr><tr><td>38</td><td>Donald Perez</td><td>28</td><td>Sales</td><td>57328.59</td><td>2017-12-30</td></tr><tr><td>39</td><td>Adrienne Gonzalez</td><td>56</td><td>IT</td><td>102891.39</td><td>2020-02-28</td></tr><tr><td>40</td><td>Joseph Shannon</td><td>50</td><td>IT</td><td>58684.97</td><td>2022-03-26</td></tr><tr><td>41</td><td>Robert Bennett</td><td>60</td><td>Marketing</td><td>84853.13</td><td>2016-11-03</td></tr><tr><td>42</td><td>Angela Diaz</td><td>35</td><td>Finance</td><td>36282.1</td><td>2019-01-25</td></tr><tr><td>43</td><td>Billy Li</td><td>52</td><td>Finance</td><td>37680.52</td><td>2024-06-10</td></tr><tr><td>44</td><td>Sean Franklin</td><td>36</td><td>Engineering</td><td>63291.29</td><td>2015-11-30</td></tr><tr><td>45</td><td>Peter Harding</td><td>57</td><td>Finance</td><td>82761.83</td><td>2019-10-21</td></tr><tr><td>46</td><td>Charles Johnson</td><td>45</td><td>Engineering</td><td>114542.55</td><td>2024-09-20</td></tr><tr><td>47</td><td>Michael Martinez</td><td>60</td><td>Finance</td><td>91040.52</td><td>2018-09-17</td></tr><tr><td>48</td><td>Joshua Johnson</td><td>38</td><td>Marketing</td><td>78569.11</td><td>2018-09-18</td></tr><tr><td>49</td><td>Kevin Lee MD</td><td>24</td><td>IT</td><td>117533.18</td><td>2017-10-04</td></tr><tr><td>50</td><td>Scott Anderson</td><td>38</td><td>Finance</td><td>41064.06</td><td>2023-06-30</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  1,
                  "Miranda Johnson",
                  58,
                  "Engineering",
                  119469.22,
                  "2022-02-21"
                ],
                [
                  2,
                  "Ryan Lee",
                  55,
                  "Engineering",
                  102336.05,
                  "2019-05-22"
                ],
                [
                  3,
                  "William Torres",
                  49,
                  "Marketing",
                  38991.2,
                  "2022-07-25"
                ],
                [
                  4,
                  "Brittany Hernandez",
                  44,
                  "IT",
                  42585.89,
                  "2019-12-07"
                ],
                [
                  5,
                  "Megan Cherry",
                  50,
                  "Finance",
                  41944.9,
                  "2024-08-02"
                ],
                [
                  6,
                  "Samuel Daniels",
                  60,
                  "Sales",
                  63854.4,
                  "2020-07-22"
                ],
                [
                  7,
                  "Harold Everett",
                  35,
                  "Finance",
                  61779.53,
                  "2021-10-29"
                ],
                [
                  8,
                  "Pam Ruiz",
                  30,
                  "Marketing",
                  118795.78,
                  "2020-06-12"
                ],
                [
                  9,
                  "Kristin Rodriguez",
                  53,
                  "Engineering",
                  86175.05,
                  "2018-07-16"
                ],
                [
                  10,
                  "Scott Murphy",
                  30,
                  "Engineering",
                  76038.39,
                  "2024-02-14"
                ],
                [
                  11,
                  "Richard Jacobs",
                  54,
                  "Marketing",
                  77725.84,
                  "2023-03-22"
                ],
                [
                  12,
                  "Keith Diaz",
                  60,
                  "Marketing",
                  81059.96,
                  "2019-07-12"
                ],
                [
                  13,
                  "Christopher Pruitt",
                  52,
                  "Sales",
                  113644.09,
                  "2019-10-18"
                ],
                [
                  14,
                  "Benjamin Carter",
                  50,
                  "Finance",
                  44996.07,
                  "2024-06-21"
                ],
                [
                  15,
                  "Joseph Everett",
                  47,
                  "Marketing",
                  43383.14,
                  "2021-11-24"
                ],
                [
                  16,
                  "Gina Martinez",
                  22,
                  "Marketing",
                  106480.2,
                  "2017-12-26"
                ],
                [
                  17,
                  "Jessica Herrera DDS",
                  51,
                  "Marketing",
                  79347.77,
                  "2017-10-11"
                ],
                [
                  18,
                  "Stephen Taylor",
                  51,
                  "Finance",
                  110841.74,
                  "2022-09-26"
                ],
                [
                  19,
                  "Danielle Kelly",
                  48,
                  "HR",
                  100780.62,
                  "2017-07-18"
                ],
                [
                  20,
                  "Dr. Christopher Steele",
                  27,
                  "Finance",
                  116648.26,
                  "2018-06-30"
                ],
                [
                  21,
                  "Kevin Leonard",
                  60,
                  "Sales",
                  77036.71,
                  "2025-01-15"
                ],
                [
                  22,
                  "Shannon Brown",
                  42,
                  "HR",
                  67540.92,
                  "2024-11-24"
                ],
                [
                  23,
                  "Joseph Perez",
                  24,
                  "IT",
                  31429.97,
                  "2024-10-31"
                ],
                [
                  24,
                  "Jessica Goodwin",
                  50,
                  "Engineering",
                  85431.77,
                  "2023-05-30"
                ],
                [
                  25,
                  "James Dunn",
                  53,
                  "Engineering",
                  75625.22,
                  "2022-09-10"
                ],
                [
                  26,
                  "Julie Welch",
                  40,
                  "Finance",
                  43267.67,
                  "2017-04-24"
                ],
                [
                  27,
                  "Darin Mcbride",
                  44,
                  "HR",
                  53767.03,
                  "2020-03-26"
                ],
                [
                  28,
                  "Kristen Thompson",
                  38,
                  "IT",
                  105263.19,
                  "2023-05-30"
                ],
                [
                  29,
                  "Erin Graves",
                  36,
                  "Sales",
                  63082.92,
                  "2023-09-14"
                ],
                [
                  30,
                  "Eric Sparks",
                  45,
                  "IT",
                  119771.68,
                  "2024-07-15"
                ],
                [
                  31,
                  "Kimberly Beasley",
                  40,
                  "Marketing",
                  79804.86,
                  "2021-06-22"
                ],
                [
                  32,
                  "Gary Brown Jr.",
                  60,
                  "Engineering",
                  72747.45,
                  "2019-05-27"
                ],
                [
                  33,
                  "Sean Lowery",
                  29,
                  "IT",
                  48469.72,
                  "2020-09-13"
                ],
                [
                  34,
                  "Andre Andrade",
                  58,
                  "Engineering",
                  116103.39,
                  "2020-01-02"
                ],
                [
                  35,
                  "Christopher Garcia",
                  27,
                  "Marketing",
                  116163.3,
                  "2018-07-20"
                ],
                [
                  36,
                  "Rachel Valentine",
                  53,
                  "Marketing",
                  107012.86,
                  "2016-11-22"
                ],
                [
                  37,
                  "Jill Tucker",
                  32,
                  "Engineering",
                  104794.25,
                  "2015-10-26"
                ],
                [
                  38,
                  "Donald Perez",
                  28,
                  "Sales",
                  57328.59,
                  "2017-12-30"
                ],
                [
                  39,
                  "Adrienne Gonzalez",
                  56,
                  "IT",
                  102891.39,
                  "2020-02-28"
                ],
                [
                  40,
                  "Joseph Shannon",
                  50,
                  "IT",
                  58684.97,
                  "2022-03-26"
                ],
                [
                  41,
                  "Robert Bennett",
                  60,
                  "Marketing",
                  84853.13,
                  "2016-11-03"
                ],
                [
                  42,
                  "Angela Diaz",
                  35,
                  "Finance",
                  36282.1,
                  "2019-01-25"
                ],
                [
                  43,
                  "Billy Li",
                  52,
                  "Finance",
                  37680.52,
                  "2024-06-10"
                ],
                [
                  44,
                  "Sean Franklin",
                  36,
                  "Engineering",
                  63291.29,
                  "2015-11-30"
                ],
                [
                  45,
                  "Peter Harding",
                  57,
                  "Finance",
                  82761.83,
                  "2019-10-21"
                ],
                [
                  46,
                  "Charles Johnson",
                  45,
                  "Engineering",
                  114542.55,
                  "2024-09-20"
                ],
                [
                  47,
                  "Michael Martinez",
                  60,
                  "Finance",
                  91040.52,
                  "2018-09-17"
                ],
                [
                  48,
                  "Joshua Johnson",
                  38,
                  "Marketing",
                  78569.11,
                  "2018-09-18"
                ],
                [
                  49,
                  "Kevin Lee MD",
                  24,
                  "IT",
                  117533.18,
                  "2017-10-04"
                ],
                [
                  50,
                  "Scott Anderson",
                  38,
                  "Finance",
                  41064.06,
                  "2023-06-30"
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "ID",
                  "type": "\"integer\""
                },
                {
                  "metadata": "{}",
                  "name": "Name",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "Age",
                  "type": "\"integer\""
                },
                {
                  "metadata": "{}",
                  "name": "Department",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "Salary",
                  "type": "\"double\""
                },
                {
                  "metadata": "{}",
                  "name": "Joining_Date",
                  "type": "\"date\""
                }
              ],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "SELECT * FROM employee_cleaned;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "5e5ca345-e3e5-4df9-b2ed-38f7623b92ce",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "p-1mOF3_BesD"
      },
      "source": [
        "### **Display the Schema of the Cleaned Employee Table**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3f6c5381-8f3b-4575-967c-4014eeaee562",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "h18A3MeLBesD",
        "outputId": "9646550a-d406-4fb2-c61f-042fb1bf5807"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>ID</td><td>int</td><td>null</td></tr><tr><td>Name</td><td>string</td><td>null</td></tr><tr><td>Age</td><td>int</td><td>null</td></tr><tr><td>Department</td><td>string</td><td>null</td></tr><tr><td>Salary</td><td>double</td><td>null</td></tr><tr><td>Joining_Date</td><td>date</td><td>null</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  "ID",
                  "int",
                  null
                ],
                [
                  "Name",
                  "string",
                  null
                ],
                [
                  "Age",
                  "int",
                  null
                ],
                [
                  "Department",
                  "string",
                  null
                ],
                [
                  "Salary",
                  "double",
                  null
                ],
                [
                  "Joining_Date",
                  "date",
                  null
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{\"comment\":\"name of the column\"}",
                  "name": "col_name",
                  "type": "\"string\""
                },
                {
                  "metadata": "{\"comment\":\"data type of the column\"}",
                  "name": "data_type",
                  "type": "\"string\""
                },
                {
                  "metadata": "{\"comment\":\"comment of the column\"}",
                  "name": "comment",
                  "type": "\"string\""
                }
              ],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "DESCRIBE employee_cleaned;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "355eb8bc-3d5c-48fb-ac54-3d340368363b",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "oathFPKaBesD"
      },
      "source": [
        "### **Get the Total Number of Records in the Cleaned Employee Table**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2aed5051-fb6f-4870-9664-039efb029554",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "I2fRuvkLBesE",
        "outputId": "8d5f8135-fd3a-4a56-a21c-9e56a57eba6d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>total_records</th></tr></thead><tbody><tr><td>50</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  50
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "total_records",
                  "type": "\"long\""
                }
              ],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "SELECT COUNT(*) AS total_records FROM employee_cleaned;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "036a877f-67a8-4512-88a2-56d0a7f90f23",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "SLe2CVE-BesJ"
      },
      "source": [
        "### **Check for Null Values in Each Column of the Employee External Table**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6d68baba-11cd-40bb-af1f-0f7a1488ca34",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "HcH4d9KqBesJ",
        "outputId": "c22760a3-e600-44b5-c7db-ef36048056b1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>null_id</th><th>null_name</th><th>null_age</th><th>null_department</th><th>null_salary</th><th>null_joining_date</th></tr></thead><tbody><tr><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  1,
                  0,
                  1,
                  0,
                  1,
                  1
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "null_id",
                  "type": "\"long\""
                },
                {
                  "metadata": "{}",
                  "name": "null_name",
                  "type": "\"long\""
                },
                {
                  "metadata": "{}",
                  "name": "null_age",
                  "type": "\"long\""
                },
                {
                  "metadata": "{}",
                  "name": "null_department",
                  "type": "\"long\""
                },
                {
                  "metadata": "{}",
                  "name": "null_salary",
                  "type": "\"long\""
                },
                {
                  "metadata": "{}",
                  "name": "null_joining_date",
                  "type": "\"long\""
                }
              ],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "SELECT\n",
        "    SUM(CASE WHEN ID IS NULL THEN 1 ELSE 0 END) AS null_id,\n",
        "    SUM(CASE WHEN Name IS NULL THEN 1 ELSE 0 END) AS null_name,\n",
        "    SUM(CASE WHEN Age IS NULL THEN 1 ELSE 0 END) AS null_age,\n",
        "    SUM(CASE WHEN Department IS NULL THEN 1 ELSE 0 END) AS null_department,\n",
        "    SUM(CASE WHEN Salary IS NULL THEN 1 ELSE 0 END) AS null_salary,\n",
        "    SUM(CASE WHEN Joining_Date IS NULL THEN 1 ELSE 0 END) AS null_joining_date\n",
        "FROM employee_external;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "488cb98b-10a5-4713-b89e-cfe3df69190d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "h1Dx5HP6BesK"
      },
      "source": [
        "### **Find Duplicate Records in `employee_cleaned` Based on Name and Department**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a0dd9831-3ee4-4d56-84ba-20f9cd178e53",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "JJcLtXCTBesM",
        "outputId": "20e815eb-ba26-4c87-80c9-19becaa275ad"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Name</th><th>Department</th><th>duplicate_count</th></tr></thead><tbody></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "Name",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "Department",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "duplicate_count",
                  "type": "\"long\""
                }
              ],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "SELECT Name, Department, COUNT(*) AS duplicate_count\n",
        "FROM employee_cleaned\n",
        "GROUP BY Name, Department\n",
        "HAVING COUNT(*) > 1;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "baa16678-666e-407f-a7fe-8a636cdbf336",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "PMMBljPABesM"
      },
      "source": [
        "### **Count Employees by Department in Descending Order**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "942c90fe-93da-46ca-9977-cc08cf915a6f",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "hll4vMfhBesM",
        "outputId": "be658e00-1131-4172-90be-fbd147cd1285"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Department</th><th>employee_count</th></tr></thead><tbody><tr><td>Marketing</td><td>12</td></tr><tr><td>Engineering</td><td>11</td></tr><tr><td>Finance</td><td>11</td></tr><tr><td>IT</td><td>8</td></tr><tr><td>Sales</td><td>5</td></tr><tr><td>HR</td><td>3</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  "Marketing",
                  12
                ],
                [
                  "Engineering",
                  11
                ],
                [
                  "Finance",
                  11
                ],
                [
                  "IT",
                  8
                ],
                [
                  "Sales",
                  5
                ],
                [
                  "HR",
                  3
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "Department",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "employee_count",
                  "type": "\"long\""
                }
              ],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "SELECT Department, COUNT(*) AS employee_count\n",
        "FROM employee_cleaned\n",
        "GROUP BY Department\n",
        "ORDER BY employee_count DESC;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "eef6598f-7faf-4e2d-8280-3c9299abf784",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "XVx9O37nBesM"
      },
      "source": [
        "### **Calculate and Sort Average Salary by Department in Descending Order**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "40287a03-ec0c-4bef-9a7b-c54b32ef8e37",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "tAON1jE5BesM",
        "outputId": "2620cb0e-6324-4192-c412-cbbbfd1144b0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Department</th><th>avg_salary</th></tr></thead><tbody><tr><td>Engineering</td><td>92414.06</td></tr><tr><td>Marketing</td><td>84348.93</td></tr><tr><td>IT</td><td>78328.75</td></tr><tr><td>Sales</td><td>74989.34</td></tr><tr><td>HR</td><td>74029.52</td></tr><tr><td>Finance</td><td>64391.56</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  "Engineering",
                  92414.06
                ],
                [
                  "Marketing",
                  84348.93
                ],
                [
                  "IT",
                  78328.75
                ],
                [
                  "Sales",
                  74989.34
                ],
                [
                  "HR",
                  74029.52
                ],
                [
                  "Finance",
                  64391.56
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "Department",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "avg_salary",
                  "type": "\"double\""
                }
              ],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "SELECT Department, ROUND(AVG(Salary), 2) AS avg_salary\n",
        "FROM employee_cleaned\n",
        "GROUP BY Department\n",
        "ORDER BY avg_salary DESC;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "c3142a3c-367e-4158-8fc1-fffa7247a3d2",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "TRfPGLnZBesN"
      },
      "source": [
        "### **Retrieve Employees with the Highest Salary in Each Department**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "32923225-ab4a-45d7-907d-0291bb8c1556",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "BtRtz--kBesN",
        "outputId": "96c003d8-ae54-4f22-add4-2ddd6ec55d37"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>Name</th><th>Age</th><th>Department</th><th>Salary</th><th>Joining_Date</th></tr></thead><tbody><tr><td>1</td><td>Miranda Johnson</td><td>58</td><td>Engineering</td><td>119469.22</td><td>2022-02-21</td></tr><tr><td>8</td><td>Pam Ruiz</td><td>30</td><td>Marketing</td><td>118795.78</td><td>2020-06-12</td></tr><tr><td>13</td><td>Christopher Pruitt</td><td>52</td><td>Sales</td><td>113644.09</td><td>2019-10-18</td></tr><tr><td>19</td><td>Danielle Kelly</td><td>48</td><td>HR</td><td>100780.62</td><td>2017-07-18</td></tr><tr><td>20</td><td>Dr. Christopher Steele</td><td>27</td><td>Finance</td><td>116648.26</td><td>2018-06-30</td></tr><tr><td>30</td><td>Eric Sparks</td><td>45</td><td>IT</td><td>119771.68</td><td>2024-07-15</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  1,
                  "Miranda Johnson",
                  58,
                  "Engineering",
                  119469.22,
                  "2022-02-21"
                ],
                [
                  8,
                  "Pam Ruiz",
                  30,
                  "Marketing",
                  118795.78,
                  "2020-06-12"
                ],
                [
                  13,
                  "Christopher Pruitt",
                  52,
                  "Sales",
                  113644.09,
                  "2019-10-18"
                ],
                [
                  19,
                  "Danielle Kelly",
                  48,
                  "HR",
                  100780.62,
                  "2017-07-18"
                ],
                [
                  20,
                  "Dr. Christopher Steele",
                  27,
                  "Finance",
                  116648.26,
                  "2018-06-30"
                ],
                [
                  30,
                  "Eric Sparks",
                  45,
                  "IT",
                  119771.68,
                  "2024-07-15"
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "ID",
                  "type": "\"integer\""
                },
                {
                  "metadata": "{}",
                  "name": "Name",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "Age",
                  "type": "\"integer\""
                },
                {
                  "metadata": "{}",
                  "name": "Department",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "Salary",
                  "type": "\"double\""
                },
                {
                  "metadata": "{}",
                  "name": "Joining_Date",
                  "type": "\"date\""
                }
              ],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "SELECT *\n",
        "FROM employee_cleaned e1\n",
        "WHERE Salary = (SELECT MAX(Salary) FROM employee_cleaned e2 WHERE e1.Department = e2.Department);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "2de2f3ca-59e2-4f83-80ab-4652f42826db",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "3Lc1yuuRBesN"
      },
      "source": [
        "### **Categorize Employees by Salary Range and Count**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "bcce3bf0-f4ad-4d5f-9820-cfb1e61866bc",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "Q55gW1VCBesN",
        "outputId": "bee9d272-34e3-44d2-e08f-a5f67415b870"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>salary_category</th><th>count</th></tr></thead><tbody><tr><td>High</td><td>23</td></tr><tr><td>Low</td><td>11</td></tr><tr><td>Medium</td><td>16</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  "High",
                  23
                ],
                [
                  "Low",
                  11
                ],
                [
                  "Medium",
                  16
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "salary_category",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "count",
                  "type": "\"long\""
                }
              ],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "SELECT\n",
        "    CASE\n",
        "        WHEN Salary < 50000 THEN 'Low'\n",
        "        WHEN Salary BETWEEN 50000 AND 80000 THEN 'Medium'\n",
        "        WHEN Salary > 80000 THEN 'High'\n",
        "    END AS salary_category, COUNT(*) AS count\n",
        "FROM employee_cleaned\n",
        "GROUP BY salary_category;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "faa2a5b8-5d3a-4884-ab07-a8db6df58301",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "WxbC_IyMBesN"
      },
      "source": [
        "### **Filter Employees Who Joined in 2023 or Later**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c0a58795-8d50-4e5e-87bf-14a6bc45143d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "TjaUarSDBesN",
        "outputId": "8119b468-086d-4910-a999-ac1acf2fb544"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .table-result-container {\n",
              "    max-height: 300px;\n",
              "    overflow: auto;\n",
              "  }\n",
              "  table, th, td {\n",
              "    border: 1px solid black;\n",
              "    border-collapse: collapse;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 5px;\n",
              "  }\n",
              "  th {\n",
              "    text-align: left;\n",
              "  }\n",
              "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>Name</th><th>Age</th><th>Department</th><th>Salary</th><th>Joining_Date</th></tr></thead><tbody><tr><td>5</td><td>Megan Cherry</td><td>50</td><td>Finance</td><td>41944.9</td><td>2024-08-02</td></tr><tr><td>10</td><td>Scott Murphy</td><td>30</td><td>Engineering</td><td>76038.39</td><td>2024-02-14</td></tr><tr><td>11</td><td>Richard Jacobs</td><td>54</td><td>Marketing</td><td>77725.84</td><td>2023-03-22</td></tr><tr><td>14</td><td>Benjamin Carter</td><td>50</td><td>Finance</td><td>44996.07</td><td>2024-06-21</td></tr><tr><td>21</td><td>Kevin Leonard</td><td>60</td><td>Sales</td><td>77036.71</td><td>2025-01-15</td></tr><tr><td>22</td><td>Shannon Brown</td><td>42</td><td>HR</td><td>67540.92</td><td>2024-11-24</td></tr><tr><td>23</td><td>Joseph Perez</td><td>24</td><td>IT</td><td>31429.97</td><td>2024-10-31</td></tr><tr><td>24</td><td>Jessica Goodwin</td><td>50</td><td>Engineering</td><td>85431.77</td><td>2023-05-30</td></tr><tr><td>28</td><td>Kristen Thompson</td><td>38</td><td>IT</td><td>105263.19</td><td>2023-05-30</td></tr><tr><td>29</td><td>Erin Graves</td><td>36</td><td>Sales</td><td>63082.92</td><td>2023-09-14</td></tr><tr><td>30</td><td>Eric Sparks</td><td>45</td><td>IT</td><td>119771.68</td><td>2024-07-15</td></tr><tr><td>43</td><td>Billy Li</td><td>52</td><td>Finance</td><td>37680.52</td><td>2024-06-10</td></tr><tr><td>46</td><td>Charles Johnson</td><td>45</td><td>Engineering</td><td>114542.55</td><td>2024-09-20</td></tr><tr><td>50</td><td>Scott Anderson</td><td>38</td><td>Finance</td><td>41064.06</td><td>2023-06-30</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "aggData": [],
              "aggError": "",
              "aggOverflow": false,
              "aggSchema": [],
              "aggSeriesLimitReached": false,
              "aggType": "",
              "arguments": {},
              "columnCustomDisplayInfos": {},
              "data": [
                [
                  5,
                  "Megan Cherry",
                  50,
                  "Finance",
                  41944.9,
                  "2024-08-02"
                ],
                [
                  10,
                  "Scott Murphy",
                  30,
                  "Engineering",
                  76038.39,
                  "2024-02-14"
                ],
                [
                  11,
                  "Richard Jacobs",
                  54,
                  "Marketing",
                  77725.84,
                  "2023-03-22"
                ],
                [
                  14,
                  "Benjamin Carter",
                  50,
                  "Finance",
                  44996.07,
                  "2024-06-21"
                ],
                [
                  21,
                  "Kevin Leonard",
                  60,
                  "Sales",
                  77036.71,
                  "2025-01-15"
                ],
                [
                  22,
                  "Shannon Brown",
                  42,
                  "HR",
                  67540.92,
                  "2024-11-24"
                ],
                [
                  23,
                  "Joseph Perez",
                  24,
                  "IT",
                  31429.97,
                  "2024-10-31"
                ],
                [
                  24,
                  "Jessica Goodwin",
                  50,
                  "Engineering",
                  85431.77,
                  "2023-05-30"
                ],
                [
                  28,
                  "Kristen Thompson",
                  38,
                  "IT",
                  105263.19,
                  "2023-05-30"
                ],
                [
                  29,
                  "Erin Graves",
                  36,
                  "Sales",
                  63082.92,
                  "2023-09-14"
                ],
                [
                  30,
                  "Eric Sparks",
                  45,
                  "IT",
                  119771.68,
                  "2024-07-15"
                ],
                [
                  43,
                  "Billy Li",
                  52,
                  "Finance",
                  37680.52,
                  "2024-06-10"
                ],
                [
                  46,
                  "Charles Johnson",
                  45,
                  "Engineering",
                  114542.55,
                  "2024-09-20"
                ],
                [
                  50,
                  "Scott Anderson",
                  38,
                  "Finance",
                  41064.06,
                  "2023-06-30"
                ]
              ],
              "datasetInfos": [],
              "dbfsResultPath": null,
              "isJsonSchema": true,
              "metadata": {
                "isDbfsCommandResult": false
              },
              "overflow": false,
              "plotOptions": {
                "customPlotOptions": {},
                "displayType": "table",
                "pivotAggregation": null,
                "pivotColumns": null,
                "xColumns": null,
                "yColumns": null
              },
              "removedWidgets": [],
              "schema": [
                {
                  "metadata": "{}",
                  "name": "ID",
                  "type": "\"integer\""
                },
                {
                  "metadata": "{}",
                  "name": "Name",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "Age",
                  "type": "\"integer\""
                },
                {
                  "metadata": "{}",
                  "name": "Department",
                  "type": "\"string\""
                },
                {
                  "metadata": "{}",
                  "name": "Salary",
                  "type": "\"double\""
                },
                {
                  "metadata": "{}",
                  "name": "Joining_Date",
                  "type": "\"date\""
                }
              ],
              "type": "table"
            }
          }
        }
      ],
      "source": [
        "%sql\n",
        "SELECT * FROM employee_cleaned WHERE YEAR(TO_DATE(Joining_Date, 'MM/dd/yyyy')) >= 2023;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "f8e66336-e0e2-466a-8082-83f5b0f43ada",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "KYSdLK02BesO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "computePreferences": null,
      "dashboards": [],
      "environmentMetadata": {
        "base_environment": "",
        "client": "1"
      },
      "language": "python",
      "notebookMetadata": {
        "mostRecentlyExecutedCommandWithImplicitDF": {
          "commandId": 4158805642970818,
          "dataframes": [
            "_sqldf"
          ]
        },
        "pythonIndentUnit": 4
      },
      "notebookName": "Hive For all",
      "widgets": {}
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}