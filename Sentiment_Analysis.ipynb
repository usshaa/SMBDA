{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usshaa/SMBDA/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a notebook outline that covers the fundamentals of sentiment analysis, including the key steps such as introduction, pre-processing the dataset, word embeddings, building a neural network, training the model, testing the model, and applying it to a single input. Each section includes detailed explanations and relevant Python code snippets.\n",
        "\n",
        "# Sentiment Analysis with Deep Learning\n",
        "\n",
        "This notebook provides a comprehensive guide to sentiment analysis using deep learning techniques. We will cover the following topics:\n",
        "\n",
        "1. Introduction to Sentiment Analysis\n",
        "2. Pre-Processing the Dataset\n",
        "3. Word Embeddings\n",
        "4. Build the Network\n",
        "5. Train the Model\n",
        "6. Test the Model\n",
        "7. Apply to a Single Input\n"
      ],
      "metadata": {
        "id": "40r5y3M6k9Nz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional Notes:\n",
        "To run this notebook successfully, ensure you have the necessary libraries installed:"
      ],
      "metadata": {
        "id": "HfTuORzMk9N4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy nltk keras tensorflow"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBuMDgPtk9N5",
        "outputId": "ff34f412-3713-40c4-d2e6-0af404956170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset:\n",
        "Make sure to provide a dataset named `sentiment_data.csv` with columns `text` and `label` where `label` is binary (0 or 1) indicating negative or positive sentiment.\n",
        "\n",
        "This structured approach will provide a clear understanding of sentiment analysis and help readers replicate the process effectively."
      ],
      "metadata": {
        "id": "Q2HAwjCuk9N7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may also need to download the NLTK stopwords using:"
      ],
      "metadata": {
        "id": "880kbLCXk9N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3b7GSR5k9N8",
        "outputId": "2d0ab244-911e-411a-d097-012eef647250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction to Sentiment Analysis\n",
        "\n",
        "**Sentiment Analysis** is a Natural Language Processing (NLP) technique used to determine the sentiment or emotional tone behind a body of text. It helps businesses and organizations understand opinions, reviews, and customer feedback.\n",
        "\n",
        "### Example Use Cases:\n",
        "- Analyzing product reviews\n",
        "- Monitoring social media sentiment\n",
        "- Customer feedback analysis\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "-a4jjGfWk9N9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Pre-Processing the Dataset\n",
        "\n",
        "Before training a model, it's essential to pre-process the text data. This step involves cleaning the text, removing noise, and preparing it for analysis.\n",
        "\n",
        "### Steps:\n",
        "- Load the dataset\n",
        "- Clean the text (remove punctuation, lowercasing, etc.)\n",
        "- Tokenization\n",
        "- Remove stop words\n",
        "- Split into training and testing sets"
      ],
      "metadata": {
        "id": "gYl6q15fk9N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "trusted": true,
        "id": "aF1ELHrtk9N9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "# (Assuming the dataset has two columns: 'text' and 'label')\n",
        "data = pd.read_csv('sentiment_data.csv')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "data.head()"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JOOLpqfwk9N-",
        "outputId": "a3e90cd3-fcbb-4ad3-e6de-012c30945da2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             text  label\n",
              "0              I love this product, it's amazing!      1\n",
              "1     This is the worst experience I've ever had.      0\n",
              "2  Absolutely fantastic service, will come again!      1\n",
              "3               I'm not happy with this purchase.      0\n",
              "4           Best purchase ever! Totally worth it.      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ebbffb4-8ee0-4266-a6de-4dfc3863b729\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love this product, it's amazing!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is the worst experience I've ever had.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Absolutely fantastic service, will come again!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I'm not happy with this purchase.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Best purchase ever! Totally worth it.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ebbffb4-8ee0-4266-a6de-4dfc3863b729')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2ebbffb4-8ee0-4266-a6de-4dfc3863b729 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2ebbffb4-8ee0-4266-a6de-4dfc3863b729');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-938d7c62-8469-411e-a4b9-03db88c0d1e8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-938d7c62-8469-411e-a4b9-03db88c0d1e8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-938d7c62-8469-411e-a4b9-03db88c0d1e8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"I can't recommend this enough!\",\n          \"This is the worst experience I've ever had.\",\n          \"I regret buying this item.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning the text\n",
        "def clean_text(text):\n",
        "    # Remove punctuation and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "    return text"
      ],
      "metadata": {
        "trusted": true,
        "id": "EdpqFfwvk9N-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply cleaning function to the dataset\n",
        "data['cleaned_text'] = data['text'].apply(clean_text)\n",
        "data['cleaned_text']"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "qi6d0YtLk9N-",
        "outputId": "8231d081-89b2-4a81-e62b-cb59dd246250"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                 i love this product its amazing\n",
              "1       this is the worst experience ive ever had\n",
              "2    absolutely fantastic service will come again\n",
              "3                 im not happy with this purchase\n",
              "4             best purchase ever totally worth it\n",
              "5                       i regret buying this item\n",
              "6          the quality is great im very satisfied\n",
              "7     terrible customer service very disappointed\n",
              "8                    i cant recommend this enough\n",
              "9                        its okay nothing special\n",
              "Name: cleaned_text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i love this product its amazing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this is the worst experience ive ever had</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>absolutely fantastic service will come again</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>im not happy with this purchase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>best purchase ever totally worth it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i regret buying this item</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>the quality is great im very satisfied</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>terrible customer service very disappointed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>i cant recommend this enough</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>its okay nothing special</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization and removing stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "data['tokenized'] = data['cleaned_text'].apply(lambda x: [word for word in x.split() if word not in stop_words])\n",
        "data['tokenized']"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "-YY63-eBk9N_",
        "outputId": "d4ebe8dd-c22f-453a-eebc-4b06e663dd7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                       [love, product, amazing]\n",
              "1                 [worst, experience, ive, ever]\n",
              "2         [absolutely, fantastic, service, come]\n",
              "3                          [im, happy, purchase]\n",
              "4         [best, purchase, ever, totally, worth]\n",
              "5                         [regret, buying, item]\n",
              "6                [quality, great, im, satisfied]\n",
              "7    [terrible, customer, service, disappointed]\n",
              "8                      [cant, recommend, enough]\n",
              "9                       [okay, nothing, special]\n",
              "Name: tokenized, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[love, product, amazing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[worst, experience, ive, ever]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[absolutely, fantastic, service, come]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[im, happy, purchase]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[best, purchase, ever, totally, worth]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[regret, buying, item]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[quality, great, im, satisfied]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[terrible, customer, service, disappointed]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[cant, recommend, enough]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[okay, nothing, special]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['tokenized'], data['label'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "trusted": true,
        "id": "rHNCD72Uk9N_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Word Embeddings\n",
        "\n",
        "**Word Embeddings** are a type of word representation that allows words to be represented as vectors in a continuous vector space. This representation captures semantic meanings of words.\n",
        "\n",
        "### Popular Word Embedding Techniques:\n",
        "- Word2Vec\n",
        "- GloVe\n",
        "- FastText\n",
        "\n",
        "For simplicity, we will use `GloVe` embeddings.\n",
        "\n",
        "```python\n",
        "# Download GloVe embeddings (example: GloVe.6B.100d)\n",
        "# Assuming the embeddings are downloaded and extracted to 'glove.6B.100d.txt'"
      ],
      "metadata": {
        "id": "MdxHjQY7k9N_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word embedding techniques are methods used to convert words into numerical vectors, allowing machines to understand and process language more effectively. Here are some popular word embedding techniques:\n",
        "\n",
        "1. **Word2Vec**:\n",
        "   - Developed by Google, Word2Vec is a predictive model that uses a neural network to learn word associations from large corpora of text. It can be trained using two architectures:\n",
        "     - **Continuous Bag of Words (CBOW)**: Predicts a target word based on its context (surrounding words).\n",
        "     - **Skip-Gram**: Predicts the surrounding context words given a target word.\n",
        "   - Produces high-dimensional dense vectors that capture semantic relationships between words.\n",
        "\n",
        "2. **GloVe (Global Vectors for Word Representation)**:\n",
        "   - Developed by Stanford, GloVe uses matrix factorization techniques on the word co-occurrence matrix. It focuses on capturing global statistical information about words in a corpus.\n",
        "   - The objective is to find word vectors such that their dot product predicts the probability of word co-occurrences.\n",
        "\n",
        "3. **FastText**:\n",
        "   - Developed by Facebook, FastText extends Word2Vec by representing each word as a bag of character n-grams. This allows it to create embeddings for out-of-vocabulary words and better capture morphological features.\n",
        "   - Useful for languages with rich morphology or when handling domain-specific terms.\n",
        "\n",
        "4. **ElMo (Embeddings from Language Models)**:\n",
        "   - Developed by AllenNLP, ELMo generates word embeddings by utilizing a deep bidirectional LSTM (Long Short-Term Memory) language model.\n",
        "   - Unlike static embeddings, ELMo produces contextualized embeddings, meaning the representation of a word can change based on its context in a sentence.\n",
        "\n",
        "5. **BERT (Bidirectional Encoder Representations from Transformers)**:\n",
        "   - Developed by Google, BERT uses a transformer architecture and is trained on masked language modeling and next sentence prediction tasks.\n",
        "   - BERT generates contextual embeddings, allowing the same word to have different representations depending on its usage in context.\n",
        "\n",
        "6. **Transformer-Based Models (e.g., GPT, RoBERTa, T5)**:\n",
        "   - Many modern NLP models based on the transformer architecture produce word embeddings as part of their internal processes. These models can capture more complex relationships and dependencies in the data due to their multi-layered structure.\n",
        "\n",
        "7. **Sentence Embeddings**:\n",
        "   - Techniques like Universal Sentence Encoder and Sentence-BERT extend word embeddings to entire sentences, enabling applications in tasks such as semantic similarity and text classification.\n",
        "\n",
        "8. **Custom Word Embeddings**:\n",
        "   - You can also create custom word embeddings using techniques like Autoencoders or Neural Networks on domain-specific data, which can provide better performance in specialized applications.\n",
        "\n",
        "Each of these techniques has its strengths and is suitable for different NLP tasks, depending on factors like the size of the corpus, the need for contextuality, and computational resources."
      ],
      "metadata": {
        "id": "vLDjru1rlcwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(file):\n",
        "    embeddings = {}\n",
        "    with open(file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.array(values[1:], dtype='float32')\n",
        "            embeddings[word] = vector\n",
        "    return embeddings"
      ],
      "metadata": {
        "trusted": true,
        "id": "DeHRREPBk9OA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "t9-wO8bbnrEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Download the GloVe embeddings (if not already downloaded)\n",
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "\n",
        "# # Unzip the downloaded file\n",
        "# !unzip glove.6B.zip\n",
        "\n",
        "# Load the embeddings, ensuring the path is correct\n",
        "glove_embeddings = load_glove_embeddings('glove.6B.100d.txt')"
      ],
      "metadata": {
        "trusted": true,
        "id": "43jGSdAxk9OA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an embedding matrix for our vocabulary\n",
        "def create_embedding_matrix(vocabulary, glove_embeddings, embedding_dim=100):\n",
        "    embedding_matrix = np.zeros((len(vocabulary), embedding_dim))\n",
        "    for i, word in enumerate(vocabulary):\n",
        "        embedding_vector = glove_embeddings.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "trusted": true,
        "id": "BxI3ObOjk9OA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a vocabulary from the training set\n",
        "vocabulary = set(word for words in X_train for word in words)\n",
        "embedding_matrix = create_embedding_matrix(vocabulary, glove_embeddings)"
      ],
      "metadata": {
        "trusted": true,
        "id": "QVdS_4V2k9OB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Build the Network\n",
        "\n",
        "Now, we will build a simple neural network using Keras to perform sentiment analysis."
      ],
      "metadata": {
        "id": "9dXuc0Cak9OB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D"
      ],
      "metadata": {
        "trusted": true,
        "id": "Lh-rk5flk9OB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "embedding_dim = 100\n",
        "max_length = 100  # Maximum length of input sequences"
      ],
      "metadata": {
        "trusted": true,
        "id": "HX1iXurhk9OC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(vocabulary), output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "MWivrU6ak9OC",
        "outputId": "7f9d22a9-5f77-4630-889f-b83d47c7e61a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │           \u001b[38;5;34m2,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ spatial_dropout1d_1                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ spatial_dropout1d_1                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,600\u001b[0m (10.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,600</span> (10.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,600\u001b[0m (10.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,600</span> (10.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Train the Model\n",
        "\n",
        "We will train the model using the training data."
      ],
      "metadata": {
        "id": "hVDxcjINk9OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the set 'vocabulary' to a list\n",
        "vocabulary_list = list(vocabulary)\n",
        "\n",
        "# Pad sequences to ensure uniform input size\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Pad sequences using the vocabulary_list for indexing\n",
        "X_train_padded = pad_sequences(X_train.apply(lambda x: [vocabulary_list.index(word) for word in x if word in vocabulary_list]), maxlen=max_length, padding='post')\n",
        "X_test_padded = pad_sequences(X_test.apply(lambda x: [vocabulary_list.index(word) for word in x if word in vocabulary_list]), maxlen=max_length, padding='post')"
      ],
      "metadata": {
        "trusted": true,
        "id": "rQu4SOlzk9OC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_padded, y_train, epochs=5, batch_size=64, validation_data=(X_test_padded, y_test), verbose=2)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhIhA47qk9OD",
        "outputId": "b60952ea-2196-4743-dd41-3a5b27d3848c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 - 0s - 245ms/step - accuracy: 0.5000 - loss: 0.7452 - val_accuracy: 0.5000 - val_loss: 0.6937\n",
            "Epoch 2/5\n",
            "1/1 - 0s - 213ms/step - accuracy: 0.5000 - loss: 0.7383 - val_accuracy: 0.5000 - val_loss: 0.6951\n",
            "Epoch 3/5\n",
            "1/1 - 0s - 166ms/step - accuracy: 0.3750 - loss: 0.8099 - val_accuracy: 0.5000 - val_loss: 0.6964\n",
            "Epoch 4/5\n",
            "1/1 - 0s - 312ms/step - accuracy: 0.5000 - loss: 0.6801 - val_accuracy: 0.5000 - val_loss: 0.6958\n",
            "Epoch 5/5\n",
            "1/1 - 0s - 162ms/step - accuracy: 0.3750 - loss: 0.6600 - val_accuracy: 0.5000 - val_loss: 0.6959\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Test the Model\n",
        "\n",
        "We will evaluate the model using the test data to check its performance."
      ],
      "metadata": {
        "id": "Gs0F5aBek9OD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test, verbose=2)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qyx9uDKJk9OD",
        "outputId": "4fa3cc7e-177c-4a86-ad03-8d894dfcf3e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - 64ms/step - accuracy: 0.5000 - loss: 0.6959\n",
            "Test Accuracy: 0.5\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Apply to a Single Input\n",
        "\n",
        "Finally, we will create a function to apply the trained model to a single input for prediction."
      ],
      "metadata": {
        "id": "wlI7D2rCk9OD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        "    # Clean the text\n",
        "    cleaned_text = clean_text(text)\n",
        "    # Tokenize and remove stop words\n",
        "    tokenized_text = [word for word in cleaned_text.split() if word not in stop_words]\n",
        "    # Convert words to indices\n",
        "    # Convert vocabulary to a list to enable indexing\n",
        "    vocabulary_list = list(vocabulary)\n",
        "    padded_text = pad_sequences([[vocabulary_list.index(word) for word in tokenized_text if word in vocabulary_list]], maxlen=max_length, padding='post')\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(padded_text)\n",
        "    return \"Positive\" if prediction[0][0] > 0.5 else \"Negative\"\n",
        "\n",
        "# Example prediction\n",
        "print(predict_sentiment(\"I love this product!\"))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9Fb18cOk9OD",
        "outputId": "aba0a5e8-9613-4de3-ff7d-ce707bd9d054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
            "Positive\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "`\n",
        "## Conclusion\n",
        "\n",
        "In this notebook, we covered the basics of sentiment analysis using deep learning techniques. We went through data pre-processing, word embeddings, building a neural network, training the model, evaluating its performance, and applying it to a single input. This is a foundational approach to sentiment analysis and can be extended and modified for more complex tasks."
      ],
      "metadata": {
        "id": "9q1cKOWEk9OE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "M06Nk9y2k9OE"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}