{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usshaa/SMBDA/blob/main/C-5.13%3A%20Introduction_to_Spark_Streaming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "23db3c03-fa49-4737-bf91-3c06cd4fe991",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "eeU71F3Pepzd"
      },
      "source": [
        "## Introduction to Spark Streaming\n",
        "\n",
        "### Overview\n",
        "\n",
        "Apache Spark Streaming is a component of Apache Spark which provides real-time data stream processing. It allows you to process live data streams using the Spark API, enabling you to build applications that can process data in real-time.\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "- **Discretized Streams (DStreams)**: The basic abstraction provided by Spark Streaming. A DStream represents a continuous stream of data. Internally, a DStream is represented as a sequence of RDDs (Resilient Distributed Datasets).\n",
        "\n",
        "- **Batch Interval**: The time duration in which a stream of data is divided into batches. For example, a batch interval of 1 second means that the incoming data is divided into 1-second chunks.\n",
        "\n",
        "### Spark Streaming Architecture\n",
        "\n",
        "1. **Input Data Sources**: Spark Streaming can read data from various sources like Kafka, Flume, Kinesis, TCP sockets, etc.\n",
        "\n",
        "2. **Stream Processing**: Once the data is ingested, it is processed using the Spark API. This can include operations like filtering, aggregation, joining, windowing, and more.\n",
        "\n",
        "3. **Output Data Sinks**: After processing, the data can be stored in various sinks such as HDFS, databases, dashboards, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "1d862274-5549-4cee-bfd2-02a69341ff6a",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "gMhc9HR8epzn"
      },
      "source": [
        "### Example of Spark Streaming\n",
        "\n",
        "Here is an example of a simple Spark Streaming application that reads data from a TCP socket and counts the number of words in each batch.\n",
        "\n",
        "1. **Initialize Spark Streaming Context**\n",
        "2. **Create DStream from a Socket Source**\n",
        "3. **Process the DStream**\n",
        "4. **Start Streaming Context**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "cda90217-f0d4-4483-afa5-6bd2e63cc35d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "beQcrAesepzp"
      },
      "source": [
        "### Data Sources\n",
        "\n",
        "Spark Streaming supports various data sources, including:\n",
        "\n",
        "- **Kafka**: For high-throughput, low-latency data streams.\n",
        "- **Flume**: For ingesting log data.\n",
        "- **Kinesis**: For processing streams from AWS.\n",
        "- **TCP Sockets**: For basic streaming from TCP sources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "27c62bbd-b72c-4e03-9e41-c27c3b1ed9c9",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "dApOLHzJepzq"
      },
      "source": [
        "### Output Sinks\n",
        "\n",
        "Processed data can be written to various sinks, such as:\n",
        "\n",
        "- **HDFS**: For scalable storage.\n",
        "- **Databases**: For structured storage.\n",
        "- **Dashboards**: For real-time visualization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "7a28df9c-083b-4628-9306-0e96f1989855",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "7MdWPz7Vepzs"
      },
      "source": [
        "### Fault Tolerance\n",
        "\n",
        "Spark Streaming provides fault tolerance by:\n",
        "- **Checkpointing**: Saving the state of the computation periodically.\n",
        "- **Data replication**: Replicating the data across multiple nodes."
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "computePreferences": null,
      "dashboards": [],
      "environmentMetadata": null,
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "13-Introduction to Spark Streaming",
      "widgets": {}
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}