{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usshaa/SMBDA/blob/main/C-3.1%3A%20HdFS_basic_Commands.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftBQI1mEkKip"
      },
      "source": [
        "##**1: HDFS (Hadoop Distributed File System)**\n",
        "- Why First?:\n",
        "  It is the foundation for Hadoop and the primary storage system.\n",
        "- Demo Focus:\n",
        "-\tSetup HDFS.\n",
        "- Basic HDFS commands (upload, download, list files, replication, etc.).\n",
        "- Use hdfs Python libraries to interact with HDFS.\n",
        "\n",
        "*   Real-Time Example: Store log files or CSV data into HDFS.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwcLKHl-k_84"
      },
      "source": [
        "## **2: Installing Hadoop and setting up in Colab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qo3XHMBl75B0"
      },
      "outputs": [],
      "source": [
        "# Install Java Development Kit (JDK)\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download Hadoop\n",
        "!wget -q https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz\n",
        "\n",
        "# Extract Hadoop\n",
        "!tar -xzf hadoop-3.3.6.tar.gz\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb--yj1tYiEV",
        "outputId": "a3b1028b-4fa7-48ca-9aa7-60a8b5bfb5dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hadoop 3.3.6\n",
            "Source code repository https://github.com/apache/hadoop.git -r 1be78238728da9266a4f88195058f08fd012bf9c\n",
            "Compiled by ubuntu on 2023-06-18T08:22Z\n",
            "Compiled on platform linux-x86_64\n",
            "Compiled with protoc 3.7.1\n",
            "From source with checksum 5652179ad55f76cb287d9c633bb53bbd\n",
            "This command was run using /content/hadoop-3.3.6/share/hadoop/common/hadoop-common-3.3.6.jar\n"
          ]
        }
      ],
      "source": [
        "# Set Hadoop environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"HADOOP_HOME\"] = \"/content/hadoop-3.3.6\"\n",
        "os.environ[\"PATH\"] = os.environ[\"PATH\"] + \":\" + os.environ[\"HADOOP_HOME\"] + \"/bin\" + \":\" + os.environ[\"HADOOP_HOME\"] + \"/sbin\"\n",
        "\n",
        "# Configure Hadoop (replace with your desired configuration)\n",
        "!echo \"export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\" >> ~/.bashrc\n",
        "!echo \"export HADOOP_HOME=/content/hadoop-3.3.6\" >> ~/.bashrc\n",
        "!echo \"export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\" >> ~/.bashrc\n",
        "\n",
        "# Source the bashrc file to apply the changes\n",
        "!source ~/.bashrc\n",
        "\n",
        "# Verify Hadoop installation\n",
        "!hadoop version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8dKh0XIar9k",
        "outputId": "cc7482b9-c8c8-4261-b582-230cb377f1e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hadoop 3.3.6\n",
            "Source code repository https://github.com/apache/hadoop.git -r 1be78238728da9266a4f88195058f08fd012bf9c\n",
            "Compiled by ubuntu on 2023-06-18T08:22Z\n",
            "Compiled on platform linux-x86_64\n",
            "Compiled with protoc 3.7.1\n",
            "From source with checksum 5652179ad55f76cb287d9c633bb53bbd\n",
            "This command was run using /content/hadoop-3.3.6/share/hadoop/common/hadoop-common-3.3.6.jar\n"
          ]
        }
      ],
      "source": [
        "!hadoop version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcfSc7X6auvU",
        "outputId": "8ebdb715-817a-4677-b965-6b14f6036246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: /content/hadoop-3.3.6/logs does not exist. Creating.\n",
            "2025-02-11 09:26:48,116 INFO namenode.NameNode: STARTUP_MSG: \n",
            "/************************************************************\n",
            "STARTUP_MSG: Starting NameNode\n",
            "STARTUP_MSG:   host = a984bd8ec502/172.28.0.12\n",
            "STARTUP_MSG:   args = [-format]\n",
            "STARTUP_MSG:   version = 3.3.6\n",
            "STARTUP_MSG:   classpath = /content/hadoop-3.3.6/etc/hadoop:/content/hadoop-3.3.6/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/commons-codec-1.15.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-codec-haproxy-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/commons-text-1.10.0.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/hadoop-auth-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-transport-classes-kqueue-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jersey-json-1.20.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/gson-2.9.0.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jetty-xml-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/kerb-core-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-x86_64.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jetty-security-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-transport-rxtx-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-transport-udt-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/zookeeper-3.6.3.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jsr305-3.0.2.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-transport-classes-epoll-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/token-provider-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/commons-net-3.9.0.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-codec-http-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/woodstox-core-5.4.0.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-codec-smtp-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jersey-server-1.19.4.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jetty-webapp-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/stax2-api-4.2.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/kerb-common-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/metrics-core-3.2.4.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jackson-core-2.12.7.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/kerb-server-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-codec-dns-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-transport-native-epoll-4.1.89.Final-linux-aarch_64.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-handler-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-codec-stomp-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/commons-cli-1.2.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-all-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jetty-io-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/zookeeper-jute-3.6.3.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jetty-http-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-codec-xml-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jetty-server-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-common-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-transport-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-transport-sctp-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/httpcore-4.4.13.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-handler-ssl-ocsp-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-transport-native-epoll-4.1.89.Final-linux-x86_64.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/kerb-client-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-codec-socks-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jetty-util-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/commons-compress-1.21.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-transport-native-unix-common-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jersey-core-1.19.4.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-transport-native-kqueue-4.1.89.Final-osx-x86_64.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/curator-recipes-5.2.0.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jsch-0.1.55.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/reload4j-1.2.22.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/re2j-1.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-resolver-dns-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/failureaccess-1.0.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/avro-1.7.7.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-codec-memcache-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-codec-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/checker-qual-2.5.2.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jetty-servlet-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/dnsjava-2.1.7.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/kerb-util-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/kerby-config-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/curator-client-5.2.0.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/kerby-util-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jsp-api-2.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/guava-27.0-jre.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-transport-native-kqueue-4.1.89.Final-osx-aarch_64.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-resolver-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/commons-configuration2-2.8.0.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/commons-io-2.8.0.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-codec-http2-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-handler-proxy-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jackson-databind-2.12.7.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/hadoop-annotations-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jetty-util-ajax-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-codec-mqtt-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/httpclient-4.5.13.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jersey-servlet-1.19.4.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-aarch_64.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-resolver-dns-classes-macos-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/jettison-1.5.4.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-buffer-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/paranamer-2.3.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/curator-framework-5.2.0.jar:/content/hadoop-3.3.6/share/hadoop/common/lib/netty-codec-redis-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/common/hadoop-kms-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/common/hadoop-nfs-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/common/hadoop-common-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/common/hadoop-registry-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/common/hadoop-common-3.3.6-tests.jar:/content/hadoop-3.3.6/share/hadoop/hdfs:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/commons-text-1.10.0.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/hadoop-auth-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jersey-json-1.20.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/gson-2.9.0.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jetty-xml-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-x86_64.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/HikariCP-java7-2.4.12.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jetty-security-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-transport-udt-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/zookeeper-3.6.3.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/commons-net-3.9.0.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-codec-http-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/woodstox-core-5.4.0.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jersey-server-1.19.4.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jetty-webapp-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/metrics-core-3.2.4.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-codec-dns-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.89.Final-linux-aarch_64.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-handler-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-all-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jetty-io-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/zookeeper-jute-3.6.3.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jetty-http-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-codec-xml-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jetty-server-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-common-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-transport-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-handler-ssl-ocsp-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.89.Final-linux-x86_64.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/okio-2.8.0.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-codec-socks-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jetty-util-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jersey-core-1.19.4.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.89.Final-osx-x86_64.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/curator-recipes-5.2.0.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/re2j-1.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/avro-1.7.7.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-codec-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jetty-servlet-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/curator-client-5.2.0.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.89.Final-osx-aarch_64.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-resolver-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/commons-configuration2-2.8.0.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-codec-http2-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jackson-databind-2.12.7.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/hadoop-annotations-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jersey-servlet-1.19.4.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-aarch_64.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/jettison-1.5.4.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-buffer-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/paranamer-2.3.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/curator-framework-5.2.0.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-codec-redis-4.1.89.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/hadoop-hdfs-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/hadoop-hdfs-client-3.3.6-tests.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.6-tests.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.6-tests.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/hadoop-hdfs-3.3.6-tests.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/hadoop-hdfs-client-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.6-tests.jar:/content/hadoop-3.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn:/content/hadoop-3.3.6/share/hadoop/yarn/lib/guice-4.0.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/asm-tree-9.4.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/websocket-servlet-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/jersey-guice-1.19.4.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/java-util-1.9.0.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/websocket-common-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/jline-3.9.0.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/websocket-client-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/objenesis-2.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/javax.inject-1.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/bcpkix-jdk15on-1.68.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/snakeyaml-2.0.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/jetty-jndi-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/jetty-plus-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/fst-2.50.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/bcprov-jdk15on-1.68.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/jna-5.2.0.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/websocket-server-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/json-io-2.5.1.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/jetty-annotations-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/jetty-client-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/asm-commons-9.4.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/websocket-api-9.4.51.v20230217.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/jersey-client-1.19.4.jar:/content/hadoop-3.3.6/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-client-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-common-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-services-core-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-api-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-server-common-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-registry-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-services-api-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-server-router-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.6.jar:/content/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.6.jar\n",
            "STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r 1be78238728da9266a4f88195058f08fd012bf9c; compiled by 'ubuntu' on 2023-06-18T08:22Z\n",
            "STARTUP_MSG:   java = 1.8.0_442\n",
            "************************************************************/\n",
            "2025-02-11 09:26:48,194 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\n",
            "2025-02-11 09:26:48,362 INFO namenode.NameNode: createNameNode [-format]\n",
            "2025-02-11 09:26:48,981 INFO namenode.NameNode: Formatting using clusterid: CID-b976658c-dedc-4d13-af98-edfacf25f03e\n",
            "2025-02-11 09:26:49,055 INFO namenode.FSEditLog: Edit logging is async:true\n",
            "2025-02-11 09:26:49,110 INFO namenode.FSNamesystem: KeyProvider: null\n",
            "2025-02-11 09:26:49,112 INFO namenode.FSNamesystem: fsLock is fair: true\n",
            "2025-02-11 09:26:49,113 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\n",
            "2025-02-11 09:26:49,122 INFO namenode.FSNamesystem: fsOwner                = root (auth:SIMPLE)\n",
            "2025-02-11 09:26:49,122 INFO namenode.FSNamesystem: supergroup             = supergroup\n",
            "2025-02-11 09:26:49,122 INFO namenode.FSNamesystem: isPermissionEnabled    = true\n",
            "2025-02-11 09:26:49,122 INFO namenode.FSNamesystem: isStoragePolicyEnabled = true\n",
            "2025-02-11 09:26:49,123 INFO namenode.FSNamesystem: HA Enabled: false\n",
            "2025-02-11 09:26:49,194 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\n",
            "2025-02-11 09:26:49,392 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000\n",
            "2025-02-11 09:26:49,392 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\n",
            "2025-02-11 09:26:49,396 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\n",
            "2025-02-11 09:26:49,396 INFO blockmanagement.BlockManager: The block deletion will start around 2025 Feb 11 09:26:49\n",
            "2025-02-11 09:26:49,399 INFO util.GSet: Computing capacity for map BlocksMap\n",
            "2025-02-11 09:26:49,399 INFO util.GSet: VM type       = 64-bit\n",
            "2025-02-11 09:26:49,401 INFO util.GSet: 2.0% max memory 2.8 GB = 57.7 MB\n",
            "2025-02-11 09:26:49,401 INFO util.GSet: capacity      = 2^23 = 8388608 entries\n",
            "2025-02-11 09:26:49,414 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled\n",
            "2025-02-11 09:26:49,414 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\n",
            "2025-02-11 09:26:49,424 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.999\n",
            "2025-02-11 09:26:49,424 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\n",
            "2025-02-11 09:26:49,424 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\n",
            "2025-02-11 09:26:49,425 INFO blockmanagement.BlockManager: defaultReplication         = 3\n",
            "2025-02-11 09:26:49,425 INFO blockmanagement.BlockManager: maxReplication             = 512\n",
            "2025-02-11 09:26:49,425 INFO blockmanagement.BlockManager: minReplication             = 1\n",
            "2025-02-11 09:26:49,425 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\n",
            "2025-02-11 09:26:49,425 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\n",
            "2025-02-11 09:26:49,425 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\n",
            "2025-02-11 09:26:49,425 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\n",
            "2025-02-11 09:26:49,540 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911\n",
            "2025-02-11 09:26:49,541 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215\n",
            "2025-02-11 09:26:49,541 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215\n",
            "2025-02-11 09:26:49,541 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215\n",
            "2025-02-11 09:26:49,562 INFO util.GSet: Computing capacity for map INodeMap\n",
            "2025-02-11 09:26:49,562 INFO util.GSet: VM type       = 64-bit\n",
            "2025-02-11 09:26:49,562 INFO util.GSet: 1.0% max memory 2.8 GB = 28.9 MB\n",
            "2025-02-11 09:26:49,562 INFO util.GSet: capacity      = 2^22 = 4194304 entries\n",
            "2025-02-11 09:26:49,565 INFO namenode.FSDirectory: ACLs enabled? true\n",
            "2025-02-11 09:26:49,565 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\n",
            "2025-02-11 09:26:49,565 INFO namenode.FSDirectory: XAttrs enabled? true\n",
            "2025-02-11 09:26:49,566 INFO namenode.NameNode: Caching file names occurring more than 10 times\n",
            "2025-02-11 09:26:49,572 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536\n",
            "2025-02-11 09:26:49,574 INFO snapshot.SnapshotManager: SkipList is disabled\n",
            "2025-02-11 09:26:49,581 INFO util.GSet: Computing capacity for map cachedBlocks\n",
            "2025-02-11 09:26:49,581 INFO util.GSet: VM type       = 64-bit\n",
            "2025-02-11 09:26:49,582 INFO util.GSet: 0.25% max memory 2.8 GB = 7.2 MB\n",
            "2025-02-11 09:26:49,582 INFO util.GSet: capacity      = 2^20 = 1048576 entries\n",
            "2025-02-11 09:26:49,594 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\n",
            "2025-02-11 09:26:49,594 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\n",
            "2025-02-11 09:26:49,594 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\n",
            "2025-02-11 09:26:49,608 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\n",
            "2025-02-11 09:26:49,608 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\n",
            "2025-02-11 09:26:49,610 INFO util.GSet: Computing capacity for map NameNodeRetryCache\n",
            "2025-02-11 09:26:49,610 INFO util.GSet: VM type       = 64-bit\n",
            "2025-02-11 09:26:49,610 INFO util.GSet: 0.029999999329447746% max memory 2.8 GB = 886.4 KB\n",
            "2025-02-11 09:26:49,610 INFO util.GSet: capacity      = 2^17 = 131072 entries\n",
            "2025-02-11 09:26:49,645 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1890577408-172.28.0.12-1739266009634\n",
            "2025-02-11 09:26:49,671 INFO common.Storage: Storage directory /tmp/hadoop-root/dfs/name has been successfully formatted.\n",
            "2025-02-11 09:26:49,838 INFO namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-root/dfs/name/current/fsimage.ckpt_0000000000000000000 using no compression\n",
            "2025-02-11 09:26:49,981 INFO namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-root/dfs/name/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .\n",
            "2025-02-11 09:26:50,000 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\n",
            "2025-02-11 09:26:50,044 INFO namenode.FSNamesystem: Stopping services started for active state\n",
            "2025-02-11 09:26:50,044 INFO namenode.FSNamesystem: Stopping services started for standby state\n",
            "2025-02-11 09:26:50,050 INFO namenode.FSImage: FSImageSaver clean checkpoint: txid=0 when meet shutdown.\n",
            "2025-02-11 09:26:50,050 INFO namenode.NameNode: SHUTDOWN_MSG: \n",
            "/************************************************************\n",
            "SHUTDOWN_MSG: Shutting down NameNode at a984bd8ec502/172.28.0.12\n",
            "************************************************************/\n"
          ]
        }
      ],
      "source": [
        "!hdfs namenode -format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q9fNMemYmDt",
        "outputId": "f505dbe6-fb80-4e2a-8305-c0b09ecefcdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting namenodes on [a984bd8ec502]\n",
            "ERROR: Attempting to operate on hdfs namenode as root\n",
            "ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.\n",
            "Starting datanodes\n",
            "ERROR: Attempting to operate on hdfs datanode as root\n",
            "ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.\n",
            "Starting secondary namenodes [a984bd8ec502]\n",
            "ERROR: Attempting to operate on hdfs secondarynamenode as root\n",
            "ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.\n",
            "Starting resourcemanager\n",
            "ERROR: Attempting to operate on yarn resourcemanager as root\n",
            "ERROR: but there is no YARN_RESOURCEMANAGER_USER defined. Aborting operation.\n",
            "Starting nodemanagers\n",
            "ERROR: Attempting to operate on yarn nodemanager as root\n",
            "ERROR: but there is no YARN_NODEMANAGER_USER defined. Aborting operation.\n"
          ]
        }
      ],
      "source": [
        "#!hdfs namenode -format\n",
        "!start-dfs.sh\n",
        "!start-yarn.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pkAn3TNae-t",
        "outputId": "7d902d10-656a-445d-c9f8-191d35d18bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1082 Jps\n"
          ]
        }
      ],
      "source": [
        "# Check if Hadoop services are running\n",
        "!jps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXAVl11wk0_x"
      },
      "source": [
        "## **3:Practicing Hadoop From Basic To Advance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRsLMAGqa-aM",
        "outputId": "55b377b5-0e35-4ab8-df39-969788df6801"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 29 items\n",
            "-rwxr-xr-x   1 root root          0 2025-02-11 09:25 /.dockerenv\n",
            "-rw-r--r--   1 root root      17294 2024-07-10 22:45 /NGC-DL-CONTAINER-LICENSE\n",
            "drwxr-xr-x   - root root       4096 2025-02-11 09:25 /bin\n",
            "drwxr-xr-x   - root root       4096 2022-04-18 10:28 /boot\n",
            "drwxr-xr-x   - root root       4096 2025-02-11 09:26 /content\n",
            "-rw-r--r--   1 root root       4332 2024-07-10 22:46 /cuda-keyring_1.1-1_all.deb\n",
            "drwxr-xr-x   - root root       4096 2025-02-07 14:31 /datalab\n",
            "drwxr-xr-x   - root root        360 2025-02-11 09:25 /dev\n",
            "drwxr-xr-x   - root root       4096 2025-02-11 09:26 /etc\n",
            "drwxr-xr-x   - root root       4096 2022-04-18 10:28 /home\n",
            "drwxr-xr-x   - root root       4096 2025-02-07 14:15 /lib\n",
            "drwxr-xr-x   - root root       4096 2025-02-07 14:14 /lib32\n",
            "drwxr-xr-x   - root root       4096 2025-02-07 14:14 /lib64\n",
            "drwxr-xr-x   - root root       4096 2024-06-27 14:20 /libx32\n",
            "drwxr-xr-x   - root root       4096 2024-06-27 14:20 /media\n",
            "drwxr-xr-x   - root root       4096 2024-06-27 14:20 /mnt\n",
            "drwxr-xr-x   - root root       4096 2025-02-07 14:44 /opt\n",
            "dr-xr-xr-x   - root root          0 2025-02-11 09:25 /proc\n",
            "drwxrwxr-x   - root root       4096 2025-02-07 14:17 /python-apt\n",
            "-r-xr-xr-x   1 root root     346012 2000-01-01 08:00 /python-apt.tar.xz\n",
            "drwx------   - root root       4096 2025-02-11 09:25 /root\n",
            "drwxr-xr-x   - root root       4096 2025-02-07 14:12 /run\n",
            "drwxr-xr-x   - root root       4096 2025-02-11 09:25 /sbin\n",
            "drwxr-xr-x   - root root       4096 2024-06-27 14:20 /srv\n",
            "dr-xr-xr-x   - root root          0 2025-02-11 09:25 /sys\n",
            "drwxrwxrwt   - root root       4096 2025-02-11 09:26 /tmp\n",
            "drwxr-xr-x   - root root       4096 2025-02-07 14:31 /tools\n",
            "drwxr-xr-x   - root root       4096 2025-02-07 14:32 /usr\n",
            "drwxr-xr-x   - root root       4096 2025-02-07 14:31 /var\n"
          ]
        }
      ],
      "source": [
        "#list down the  current directory\n",
        "!hdfs dfs -ls /"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79rOxOh4xOYI",
        "outputId": "3db62868-011b-4db3-8293-9acebee795f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1154 Jps\n",
            "35.239.134.91"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# ... (Your existing code) ...\n",
        "\n",
        "# Check if Hadoop services are running\n",
        "!jps\n",
        "\n",
        "# Find the IP address of the Colab instance\n",
        "!curl -s ifconfig.me"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUvaRQ93B9-b"
      },
      "source": [
        "# Create a directory in HDFS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_FR8_bBqbFws"
      },
      "outputs": [],
      "source": [
        "\n",
        "!hdfs dfs -mkdir -p /content/new_folder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfs dfs -touchz /content/new_folder/sample.txt"
      ],
      "metadata": {
        "id": "r_BhhMcwVw_l"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpA7nbu2B_Or"
      },
      "source": [
        "# Upload a file to HDFS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfs dfs -put -f <(echo \"I am learning hdfs cmd\") /content/new_folder/sample.txt"
      ],
      "metadata": {
        "id": "nEInhwKJWgPm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfs dfs -cat /content/new_folder/sample.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_84IB8XXwXs",
        "outputId": "f81e468c-efcd-4e23-d590-a9812a3b566d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am learning hdfs cmd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fMTzcfm1dPb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87510fd2-65f5-489b-bab4-7fbc54f9c293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "put: `sample.txt': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# !hdfs dfs -put sample.txt /content/new_folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7Nvf7yzCAYg"
      },
      "source": [
        "#List files in a directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2BwhDORek5T",
        "outputId": "d456dd00-7183-44bc-8753-5a7a2a7a8a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2 items\n",
            "drwxr-xr-x   - root root       4096 2025-02-11 09:28 /content/new_folder/.ipynb_checkpoints\n",
            "-rw-r--r--   1 root root         23 2025-02-11 09:36 /content/new_folder/sample.txt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!hdfs dfs -ls /content/new_folder/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aBFOi2VCBz6"
      },
      "source": [
        "# Displaying the content of file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtiU_GIbevPD",
        "outputId": "86ef15bf-24f7-4efe-a589-95f3fa233072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am learning hdfs cmd\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!hdfs dfs -cat /content/new_folder/sample.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l03Ss8rCDTE"
      },
      "source": [
        "# Create and write to a new file in the new_folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME2Zce5Ui9Wh"
      },
      "outputs": [],
      "source": [
        "\n",
        "with open('/content/new_folder/new_sample.txt', 'w') as f:\n",
        "    f.write(\"This is a new sample text in the newly created file.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIdm2M98CEiL"
      },
      "source": [
        "# Verifying the file is created or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVm2FVVwjCB7",
        "outputId": "9cf3b650-16aa-4e73-9a8c-86c4091a1450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2 items\n",
            "-rw-r--r--   1 root root         52 2024-12-20 10:10 /content/new_folder/new_sample.txt\n",
            "-rw-r--r--   1 root root         55 2024-12-20 10:06 /content/new_folder/sample.txt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!hdfs dfs -ls /content/new_folder/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SfRoLN8kJFC"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6c4OuUaCGCU"
      },
      "source": [
        "# Displaying the content of updated file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS5qNjnOjOB5",
        "outputId": "8ef448d0-85c3-457d-f051-ac341e67b4a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a new sample text in the newly created file."
          ]
        }
      ],
      "source": [
        "\n",
        "!hdfs dfs -cat /content/new_folder/new_sample.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isLWh-cMCHYs"
      },
      "source": [
        "# Downloading the file to local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "n5VVqFBNjYWY"
      },
      "outputs": [],
      "source": [
        "\n",
        "!hdfs dfs -put /content/new_folder/sample.txt /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRQv9UoCCIgi"
      },
      "source": [
        "# Removing the old file from the newfolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uUIKSZdlPR5",
        "outputId": "0c0151c8-a7e7-4de9-8332-c88490e3d135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-12-20 10:21:18,213 INFO Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum\n",
            "Deleted /content/new_folder/sample.txt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!hdfs dfs -rm /content/new_folder/sample.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrqzvxyJmGLK"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}