{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usshaa/SMBDA/blob/main/C-5.9%3A%20Predictive_Model_For_Countries_GDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "05b473c2-2b39-4c06-857a-ffec1478f5ba",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "eyTIm9Imdoqb"
      },
      "source": [
        "### Predict the GDP of Malaysia\n",
        "\n",
        "**Objective:** Training and evaluating a machine learning model to predict the GDP of Malaysia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "64bae8ea-dbf5-4392-9802-dad9a1ceebb4",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "TnywKWNddoqh"
      },
      "source": [
        "- **Step 1:** Import necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "014f02ea-0306-4a82-b643-ab7b4123b9e1",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "eCEFLVM3doqi"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import rand, col\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression, LinearRegressionModel\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "909a487e-c4a7-488c-9be9-f411eb7db10b",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "xl4736lfdoql"
      },
      "source": [
        "- **Step 2: Initialize Spark Session**: Starts a Spark session to utilize Spark's distributed computing capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "28a04baf-0e6d-4970-99eb-006f52273e45",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "585bmBDcdoqm"
      },
      "outputs": [],
      "source": [
        "# Step 2: Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Malaysia GDP Prediction\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "42b46bde-7972-4733-a2f2-d8efc5fc1fad",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "H3Re21PGdoqm"
      },
      "source": [
        "- **Step 3: Load and Prepare Data**: Reads the synthetic dataset into a Spark DataFrame and prepares it for feature engineering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c4b79177-eb5f-4a3c-ab14-9e045d4d7c0d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "SV7N583Ndoqn"
      },
      "outputs": [],
      "source": [
        "# Step 3: Load and Prepare Data\n",
        "data = spark.read.csv(\"/FileStore/tables/malaysia_gdp_dataset.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "9bd78c5b-966d-4515-ba12-0c07cf54c0c2",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "IMu2bhPBdoqr"
      },
      "source": [
        "- **Step 4: Feature Engineering**: Uses `VectorAssembler` to combine selected feature columns into a single vector column named \"features\", which is required for model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ed31b36e-e086-4b67-9278-672506b867b8",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "QorN3MFCdoqs"
      },
      "outputs": [],
      "source": [
        "# Step 4: Feature Engineering\n",
        "feature_columns = [\"Year\", \"Population\", \"GDP_Per_Capita\", \"Employment_Rate\", \"Inflation_Rate\", \"Interest_Rate\"]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data).select(\"features\", \"GDP\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "5250363c-364f-4fb8-9a98-ff673c0fbce5",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "dqXPjkBzdoqu"
      },
      "source": [
        "- **Step 5: Build and Train Regression Model**: Initializes a Linear Regression model (`LinearRegression`) from PySpark's machine learning library (`pyspark.ml`). The model is trained using the prepared dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3c4b238d-d16a-4824-bf5a-de825230b26e",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "8o5qix1Kdoqu"
      },
      "outputs": [],
      "source": [
        "# Step 5: Build and Train Regression Model\n",
        "lr = LinearRegression(labelCol=\"GDP\")\n",
        "model = lr.fit(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "95f91883-c697-43a9-ac8f-42c4cc950316",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "BhvlycX3doqw"
      },
      "source": [
        "- **Step 6: Evaluate the Model**: Makes predictions on the dataset and evaluates the model's performance using the Root Mean Squared Error (RMSE). This metric assesses how well the model predicts the actual GDP values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "352a2c4c-ce32-4a4f-971b-ac8535b35960",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "RCbJcHobdoqx",
        "outputId": "906b5b7f-37ff-480c-e1e3-bf88fc2c1b04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 110531700877.20\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Evaluate the Model\n",
        "predictions = model.transform(data)\n",
        "evaluator = RegressionEvaluator(labelCol=\"GDP\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "81ee0a4f-40a0-4fe2-9e0e-980e463d25ff",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "YvSiRp0Bdoqz",
        "outputId": "2d8bf18b-4562-4544-cfb6-92d3421e9d89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n|          prediction|                 GDP|            features|\n+--------------------+--------------------+--------------------+\n|3.002323404232118E11|2.713512052938978E11|[2020.0,3.4842850...|\n| 3.01690923543166E11|2.482283504872224...|[2003.0,2.9599996...|\n|3.080621710125841E11|3.023843158708312E11|[2000.0,2.8354246...|\n|2.717016765072492...|2.364924699445132...|[2023.0,3.0269213...|\n| 2.77660559956756E11|4.398302507998309...|[2008.0,3.2642778...|\n+--------------------+--------------------+--------------------+\nonly showing top 5 rows\n\n"
          ]
        }
      ],
      "source": [
        "predictions.select(\"prediction\", \"GDP\", \"features\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c39f1fae-2694-40b3-ab93-3f18da9844ee",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "hQXdiDHYdoq2",
        "outputId": "bab2b21f-5950-49f4-9cb0-6622c071da63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n|            features|                 GDP|          prediction|\n+--------------------+--------------------+--------------------+\n|[2020.0,3.4842850...|2.713512052938978E11|3.002323404232118E11|\n|[2003.0,2.9599996...|2.482283504872224...| 3.01690923543166E11|\n|[2000.0,2.8354246...|3.023843158708312E11|3.080621710125841E11|\n|[2023.0,3.0269213...|2.364924699445132...|2.717016765072492...|\n|[2008.0,3.2642778...|4.398302507998309...| 2.77660559956756E11|\n|[2007.0,3.1639998...|4.289323672360232...|3.105909635989288...|\n|[2007.0,2.3435721...|1.422155482575994...|3.231072249304668E11|\n|[2004.0,2.0481503...|4.843150268858315E11|3.049732129893963...|\n|[2023.0,2.4731795...|3.542340424405783...|3.028531706361333E11|\n|[2003.0,2.4016113...|4.314829244009833E11|3.171629143155991E11|\n|[2021.0,2.3164742...|3.829234574824308E11|2.922898454102738E11|\n|[2023.0,3.4143645...|2.741948580030708E11|2.656274607829859...|\n|[2017.0,3.3145514...|3.935181216053567...|2.812079471667381...|\n|[2002.0,2.4720168...|4.861894924952311E11|3.077443590707097E11|\n|[2018.0,2.9831579...|2.080329585549603...|2.758905073620331E11|\n|[2013.0,2.5934478...|4.232796875227024E11|2.922188296188342E11|\n|[2001.0,3.3718213...|3.152691625793023E11|2.866361271018789E11|\n|[2000.0,2.6882777...|2.933990015532785E11|2.981640994593752...|\n|[2002.0,2.3973202...|2.742297972015577...|2.957006502185314E11|\n|[2006.0,2.3699412...|3.924104857220489E11|2.945002875895544...|\n+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
          ]
        }
      ],
      "source": [
        "predictions.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "b0effb58-ae75-4784-9162-d288fc6c2475",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "HBMv6Q-xdoq3"
      },
      "source": [
        "- **Step 7: Save and Load Model (Optional)**: Optionally, saves the trained model for future use and demonstrates how to load it if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2780f384-a137-433c-a6bf-c80236eb28dc",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "5EL-E94odoq4"
      },
      "outputs": [],
      "source": [
        "# Step 7: Save and Load Model\n",
        "model.save(\"/FileStore/tables/malaysia_gdp_prediction_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "9e6d3675-2827-4af1-84df-503a9ae6a4c4",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "t09Cy_AOdoq6"
      },
      "source": [
        "### 1. Prepare the New Sample Data\n",
        "\n",
        "First, prepare your new sample data in a format that matches the input features used by your Spark Linear Regression model. Based on your provided example data, the features likely include Year, Population, GDP_Per_Capita, Employment_Rate, Inflation_Rate, and Interest_Rate.\n",
        "\n",
        "Here's an example of how you might structure the new sample data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "29972816-e5ff-4d82-b1da-5dd598331261",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "7Nkky3Jqdoq6"
      },
      "outputs": [],
      "source": [
        "# Example of new sample data\n",
        "new_sample = [\n",
        "    (2024, 36000000.0, 6800.0, 73.0, 6.0, 2.0),  # Adjust values accordingly\n",
        "    (2025, 36500000.0, 6900.0, 74.0, 5.5, 1.8),  # Another example row\n",
        "    # Add more rows as needed\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "d3348741-6406-4430-86ce-228106bec6a5",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "-1NYLSn3doq7"
      },
      "source": [
        "### 2. Convert Data to DataFrame\n",
        "\n",
        "Convert the new sample data into a DataFrame format that Spark can work with. Assuming you are using PySpark, you would create a DataFrame like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b7b361ec-372a-4d29-8c91-d28768be038a",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "X-WasjdSdoq_"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, DoubleType, IntegerType\n",
        "\n",
        "# Example schema based on your features\n",
        "schema = StructType([\n",
        "    StructField(\"Year\", IntegerType(), True),\n",
        "    StructField(\"Population\", DoubleType(), True),\n",
        "    StructField(\"GDP_Per_Capita\", DoubleType(), True),\n",
        "    StructField(\"Employment_Rate\", DoubleType(), True),\n",
        "    StructField(\"Inflation_Rate\", DoubleType(), True),\n",
        "    StructField(\"Interest_Rate\", DoubleType(), True),\n",
        "])\n",
        "\n",
        "# Create a Spark session\n",
        "# spark = SparkSession.builder.appName(\"GDPPrediction\").getOrCreate()\n",
        "\n",
        "# Convert list of tuples to DataFrame\n",
        "df = spark.createDataFrame(new_sample, schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f42c1780-423a-4bd7-a29a-c1c0692904be",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "3WAzTS2udorB"
      },
      "outputs": [],
      "source": [
        "# Assuming these are the input features you want to use\n",
        "input_features = [\"Year\", \"Population\", \"GDP_Per_Capita\", \"Employment_Rate\", \"Inflation_Rate\", \"Interest_Rate\"]\n",
        "\n",
        "# Create a VectorAssembler instance\n",
        "assembler = VectorAssembler(inputCols=input_features, outputCol=\"features\")\n",
        "\n",
        "# Transform the new sample data\n",
        "df = assembler.transform(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "888c11ab-e644-41b5-b2ad-2cc3889ca976",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "7seW9JmudorC"
      },
      "source": [
        "### 3. Load the Trained Model\n",
        "\n",
        "Load your pre-trained Spark Linear Regression model. Make sure you have saved your model after training using Spark's `save()` method or any other suitable method, and now you can load it for inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d5238e8b-d399-4a87-820e-434c52a30765",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "zGlePRvBdorC"
      },
      "outputs": [],
      "source": [
        "# Assuming 'model_path' is the path where your trained model is saved\n",
        "model = LinearRegressionModel.load(\"/FileStore/tables/malaysia_gdp_prediction_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "7f2f4969-47ed-4209-9e33-09af8377d03b",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "tsEAq1_HdorC"
      },
      "source": [
        "### 4. Transform and Predict\n",
        "\n",
        "Use the loaded model to transform the new sample data and make predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3b90ba73-84f5-4b5c-9712-858d6576b171",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "ICvViKSDdorE",
        "outputId": "4817e8f8-3cc7-40a4-f148-440b648a076c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+\n|Year|          Prediction|\n+----+--------------------+\n|2024|2.962294960213685E11|\n|2025|2.962315011918384E11|\n+----+--------------------+\n\n"
          ]
        }
      ],
      "source": [
        "# Transform the new data\n",
        "predictions = model.transform(df)\n",
        "\n",
        "# Show the predictions\n",
        "predictions.select(\"Year\", \"Prediction\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "ebc13538-0ef1-41ca-898d-f1f065ec7272",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "IDyUnkVRdorF"
      },
      "source": [
        "- **Step 8: Stop Spark Session**: Terminates the Spark session to release resources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "82149c0d-db78-475b-a750-ffb539a09826",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "MrE-az73dorF"
      },
      "source": [
        "# !Great Job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "7d148cce-d597-42f1-92fc-9c4210fdc58b",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "MnUSfPjldorG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "computePreferences": null,
      "dashboards": [],
      "environmentMetadata": null,
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "09-Predictive Model For Countries GDP",
      "widgets": {}
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}